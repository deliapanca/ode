\documentclass[a4paper,12pt]{report}
\usepackage[utf8]{inputenc}
\usepackage[none]{hyphenat}
\usepackage{amssymb,amsfonts,latexsym,makeidx}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{enumerate}

\newtheorem{theorem}{Theorem}[subsection]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem*{remark}{Remark}
\newtheorem{definition}{Definition}[subsection]
\newcommand{\R}{\mathbb{R}}
\newcommand{\M}{\mathcal{M}_{2}}
\newcommand{\xstar}{x^{*}}
\usepackage{setspace}
\usepackage{etoolbox}
\usepackage{afterpage}
\setcounter{secnumdepth}{3}
\newcommand\blankpage{%
    \null
    \thispagestyle{empty}%
    \addtocounter{page}{-1}%
    \newpage}



\setcounter{tocdepth}{2}
\begin{document}
 \begin{titlepage}
 
	\centering
	\includegraphics[width=0.25\textwidth]{Facultate1.jpg}\par\vspace{1cm}
	{\scshape\LARGE Babe\c{s}-Bolyai University Cluj-Napoca\\ Faculty of Mathematics and Computer Science \\ Mathematics specialization \par}
	\vspace{1cm}
	{\scshape\Large Bachelor's thesis\par}
	\vspace{1.5cm}
	{\huge\bfseries Differential Equations with Applications to Economics\par}
	\vspace{2cm}
	{\Large\itshape Delia P\^{a}nc\u{a}\par}
	\vfill
	supervised by\par
	Prof. Dr.  \textsc{Adrian Petru\c{s}el}

	\vfill

% Bottom of the page
	{2018}
\end{titlepage}
\begin{flushleft}

\text{Babe\c{s}-Bolyai University Cluj-Napoca}
\text{Faculty of Mathematics and Computer Science }

\vspace{20mm}
\text{Copyright © 2018, Delia P\^{a}nc\u{a}. }\par
\vspace{10mm}
\text{All rights reserved.}\par
\vspace{15mm}
The author hereby to Babe\c{s}-Bolyai University Cluj-Napoca permission to reproduce and  to distribute publicly paper and electronic copies of this thesis document in whole or in part.



\end{flushleft}
 \pagenumbering{gobble}
 \tableofcontents
 %\afterpage{\blankpage}
 %gobble = no numbers
 % arabic=arabic numbers
 %roman = roman numbers

 \blankpage


\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}
 The approach of some economic models from a mathematical perspective began in the 19th century. The economic analysis studied at that time will be later referred to as classical economy. The subjects were discussed and approached from an algebraic perspective, while the rest of the fields were ignored. Today, the theory of dynamic systems has become an essential tool in economic analysis, especially due to the modern computers. Some who lack the basic notions and the understanding of modern results from the theory of dynamic systems might find difficult to digest economic models. \par
 Many economic models which depend on the temporal dimension involve the relationship between the exchange rate of a variable and its value at a certain time. For example, a model regarding the dynamic of the price presuppose that the exchange rate of the price is proportional to the difference between the demand and supply of the price and a model for economic growth from macroeconomics presuppose that the exchange rate of the capital stock means a constant fraction of the production value. When time is discreetly modeled (i.e. takes the values 1,2,3,…), relationships like this can modelled using difference equations. When time is modeled as a continuous variable, they can be described using differential equations.\par
 The present bachelor’s thesis proposes to present some results from the theory of discrete and continuous dynamic systems and to justify their use in the real world through the description of some economic models like: price and demand (microeconomics), Keynesian model and IS-LM (macroeconomics).\par
 The purpose of the thesis is to recall some results from the theory of differential equations and the theory of difference equations. This will be considered from the theory of discrete and continuous dynamic systems point of view and some theoretical and practical examples (applies in economy) will be given for a better understanding of the notions.\par
The first chapter presents a few classes of differential equations,essential for understanding economic models: equations with separable variables, linear equations of first order and linear systems of differential equations. Inside of the linear systems of differential equations section, notions and results from matrix analysis theory, results regarding the existence and uniqueness of a solution, representations of the solutions and the case of systems of differential equations with constant coefficients will be introduced. Hereinafter, the notion of dynamic system will be presented and this theory’s auxiliary concepts: fixed point, limit sets and attractors, dynamic systems in real space, phase portraits and representations of trajectories described by  dynamic systems of differential equations generated using Maple. The chapter ends with the presentations of the IS-LM dynamics.\par
The second chapter presents difference equations of first order. The general classes of equations will be described, and also the particular cases of the general form. Later, some dynamic systems generated by difference equations will be presented, as well as dynamics generated by difference equations, stability criteria and Cobweb diagram. In the examples section, some mathematical models which use difference equations can be found, which are: depreciation, a demand and supply model, the linear Cobweb model and the Keynesian cross diagram.\par
Our contributions at the realization of this thesis consist in the selection and structure of the whole scientific material, the selection and solving the examples and the problems at the end of each chapter. For this aim, all the bibliographic sources mentioned at the end of the work were used.

 


 \chapter{Ordinary Differential Equations and Linear Systems}
 \pagenumbering{arabic}
 %\nopagebreak
 \section{Introduction}
 This chapter presents several classes of differential equations: equations with separable variables, system of linear differential equations of first order, system linear differential equations. Then, we will present some results regarding the existence and uniqueness of a solution, as well as its possible representation. In the end, we will present the case of systems of linear differential equations with constant coefficients and its particular cases.
 The author's contribution is the selection and solving of the examples found at the end of the chapter.
 \section{Equations with separable variables}\label{1.1.1}

 \subsection{The general form of an equation with separable variables}
 Let us consider the equation:
 \begin{equation}
  x'=f(t)g(x) \label{SE} \tag{SE}
 \end{equation}
 where $f:(t_1,t_2)\subset \R \rightarrow \R$ and $g:(x_1,x_2)\subset \R \rightarrow \R$ are continuous functions and g does not vanish on $(x_1,x_2)$.
 Before showing how to solve \eqref{SE}, we recall the following definition:
 We denote, for $I\subseteq \R$ an interval, the following sets:
 \begin{align*}
  C(I,\R)&:=\{x:I\rightarrow\R|x\text{ is continuous on I}\}\\
  C^{1}(I,\R^{n})&:=\{x:I\rightarrow\R^{n}|x\text{ is continous and differentible on }I\text{ and }x'\text{ is continous on }I\}
 \end{align*}
For $n=1$ we write $C(I,\R):=C(I)$ and $C^{1}(I,\R):=C^{1}(I)$.
 \begin{definition}
  We call a solution on the interval $I \subset \R$ for the differential equation $F(t,x,x')=0$ (where $F$ is a real function defined on an open set from $\R^3$) a function
 $x\in C^{1}(I)$ and which verifies the equation on $I$, meaning:
  \begin{equation}
   F(t,x(t),x'(t))=0, \forall t\in I \nonumber
  \end{equation}

 \end{definition}
 
It is understood that $x$ is such as $(t,x(t),x'(t))$ is in the domain of function $F$ for $t\in I$.
When reffering to a solution, we will usually point the interval on which it is defined (even the maximal interval if possible).
\newline\newline

We return now to \eqref{SE}.
We assume that $x=x(t)$,$t\in(t_1,t_2)$ is a solution for \eqref{SE}. Then
\begin{equation}
 \int_{x_0}^{x(t)}\frac{d\xi}{g(\xi)} = \int_{t_0}^{t}f(s)ds, t\in (t_1,t_2) \label{1.1} \tag{1.1}
\end{equation}
where $t_0$ is a random point from the interval $(t_1,t_2)$ and $x_0=x(t_0)$. We define
\begin{equation}
 G(y)=\int_{x_0}^{y}\frac{d\xi}{g(\xi)}, y\in(x_1,x_2) \label{1.2} \tag{1.2}
\end{equation}
knowing that G is a differentiable function (with continuous derivative) on $(x_1,x_2)$ and strictly monotone. Therefore we can talk about $G^{-1}$, defined on the set $G((x_1,x_2))$
which has the same properties as function $G$. Since relation \eqref{1.1} can be written:
\begin{equation}
 G(x(t))=\int_{t_0}^{t} f(s)ds, t\in(t_1,t_2) \label{1.3}\tag{1.3}
\end{equation}
results that solution $x$ has the following expression:
\begin{equation}
 x(t)=G^{-1}\bigg(\int_{t_0}^{t} f(s)ds\bigg), t\in(t_1,t_2) \label{1.4}\tag{1.4}
\end{equation}
Reversely, a function $x=x(t)$ defined by relation \eqref{1.4} (where $x_0$ is arbitrary in $(x_1,x_2)$ and $t$ goes through a neighbourhood of point $t_0$ such that $\int_{t_0}^{t} f(s)ds$ is
in the domain of function $G^{-1}$) is a solution for \eqref{SE}, also checking the Cauchy condition $x(t_0)=x_0$.


\subsection{Examples}
$1)$ 
      $\begin{cases}
       xx'=e^{-t}, t\in\R\\
       x(0)=e\\
      \end{cases}$\\\\
      \underline{Solution:} Let us consider first the equation $xx'=e^{-t}$. Then we have $$x\frac{dx}{dt}=e^{-t}.$$
      Separating the variables, we obtain $$xdx=e^{-t}dt.$$ By integration, we get: $$\int xdx =\int e^{-t}dt \Leftrightarrow$$ $$\frac{x^{2}}{2}=-e^{-t}+c_{1}, c_{1}\in \R.$$
      $$x^{2}=-2e^{-t}+c, c\in \R.$$
      This form represents the general solution in implicit form. We impose the Cauchy condition $x(0)=e.$ Then $$x^{2}=-2e^{0}+c.$$ Hence $e^{2}=-2+c.$ Thus $c=e^{2}+2$. Hence the solution in implicit form is $$x^{2}=-2e^{-t}+e^{2}+2.$$ Hence $$x=\pm\sqrt{-2e^{-t}+e^{2}+2},\text{ with }-2e^{-t}+e^{2}+2\geq 0.$$ We choose $x=\sqrt{-2e^{-t}+e^{2}+2}.$ Thus, for $t\geq ln\frac{2}{e^{2}+2}$ we have the solution: $$x=\sqrt{2(1-e^{-t})+e^{2}}.$$
      
$2)$ $x'=x^{2}-x$, $t\in \R.$ We consider the equation: $$x'=x(x-1).$$ For $x\neq0$ and $x\neq1$ we can separate the variables: $$\frac{1}{x(x-1)}dx=dt.$$ By integrating, we obtain: $$\int \frac{1}{x(x-1)} dx = \int dt.$$ $\Leftrightarrow$ $$\int \bigg(\frac{1}{x-1}-\frac{1}{x}\bigg)dx=t+c_{1}, c_{1} \in \R.$$ Next, resolving the integrals, we get:
$$ln|x-1|-ln|x|=t+c_{1},$$ $$ln|\frac{x-1}{x}|=t+c_{1}$$ $\Leftrightarrow$ $$|\frac{x-1}{x}|=c_{2}e^{t}, c_{2} \in \R.$$ $$\frac{x-1}{x}=\pm c_{2} e^{t}.$$ We can consider $\pm c_{2}$ a constant $c \in \R^{*}$. Then, the implicit form of the solution is: $$\frac{x-1}{x}=ce^{t}, c\in \R^{*}.$$ Next, $x-1=xce^{t}$, resulting that 

\begin{equation}
x=\frac{1}{1-ce^{t}}, c\in \R^{*}.
\end{equation}
We also notice that $x(t)=0$ and $x(t)=1$, where $t\in \R$ are solution for our equation. For $c=0$ in \eqref{1.1} we get $x(t)=1$. Hence the solutions are $$x(t)=0, t\in\R$$ $$x(t)=\frac{1}{1-ce^{t}}, c\in \R, t\in J$$ where $J$ is defined by the restriction $1-ce^{t}=0$.
\begin{enumerate}[(i)]
 \item $c \in R$ $\Rightarrow$ $e^{t}=\frac{1}{c}\Rightarrow$
 \begin{enumerate}[(a)]
  \item $c>0\Rightarrow e^{t}=\frac{1}{c} \Leftrightarrow t=\ln{\frac{1}{c}}=-\ln {c}$ $\Rightarrow x(t)=\frac{1}{1-ce^{t}},$ $t\in (-\infty,-\ln{c})$ or $t\in (-\ln{c},+\infty)$.
  \item $c<0$ $\Rightarrow e^{t}=\frac{1}{c} \Leftrightarrow t\in \emptyset$ $\Rightarrow x(t)=\frac{1}{1-ce^{t}}, t\in \R$
 \end{enumerate}
 \item $c=0 \Rightarrow x(t)=1, t\in \R.$
\end{enumerate}
For example, if we have a Cauchy problem of the following form:
$\begin{cases}
  x'=x^{2}-x\\
  x(0)=2
 \end{cases}
$
then $x(t)=0$ and $x(t)=1$, $t\in \R$ are not solutions.\\
For $x(t)=\frac{1}{1-ce^{t}}$: $$x(0)=2 \Leftrightarrow \frac{1}{1-c}=2 \Leftrightarrow 1-c=\frac{1}{2} \Leftrightarrow c=\frac{1}{2}.$$ In conclusion, the solution for the given Cauchy problem is:$$x(t)=\frac{1}{1-\frac{1}{2}e^{t}}, t\in (-\infty,-\ln{2}).$$


\section{Linear differential equations of first order}

The following section introduces the general method of solving linear differential equations of first order, the solving method used in practice and a few examples.

\subsection{The General Form of a linear differential equation of first order}

A linear differential equation has the following expression:

\begin{equation}
 x'=a(t)x+b(t) \label{LE} \tag{LE}
\end{equation}

where $a,b: (t_1,t_2) \subset \R\rightarrow\R$ are continous on $(t_1,t_2)$ (bounded or not). If $x=x(t)$, $t_1<t<t_2$ is a solutions for \eqref{LE}, then
multiplying with $exp(-\int_{t_0}^{t} a(s)ds)$, where $t_0$ is arbitrary chosen from $(t_1,t_2)$, the following equation is obtained
\begin{equation*}
 \frac{d}{dt}\bigg[ e^{-\int_{t_0}^{t} a(s)ds}x(t)\bigg] = b(t)e^{-\int_{t_0}^{t} a(s)ds}, t \in (t_1,t_2) 
\end{equation*}

So

\begin{equation}
 x(t)=e^{\int_{t_0}^{t} a(s)ds}x_0 + \int_{t_0}^{t} b(s)e^{-\int_{t_0}^{s} a(\sigma)d\sigma}ds , t \in (t_1,t_2) \label{SOL} \tag{SOL}
\end{equation}

where $x_0$ is an arbitrary real number. Reciprocally, we can easily agree that any function $x=x(t), t\in (t_1,t_2)$ given by the formula \eqref{SOL} is a solution for \eqref{LE}.
Actually, \eqref{SOL} asserts the solution of \eqref{LE} with the Cauchy condition $x(t_0)=x_0$.

Sometimes, it is more convienent to use the following form of \eqref{SOL}:

\begin{equation}
 x(t)= e^{\int a(s)ds}\cdot\int b(t)e^{-\int a(t) dt}dt \label{SOL*}\tag{SOL*}
\end{equation}

with the convention that $\int a(t) dt$ is a fixed primitive of $a=a(t)$ (the same in \eqref{SOL} and \eqref{SOL*}).

In practice, a method that does not require the use of \eqref{SOL} formula is based on the algebraic link which exists between the set of the \eqref{LE} solutions and the set of the associated homogeneous equation solutions: $$x'=a(t)x.$$
This link is contained in the following theorem:
\begin{theorem}\label{1.2.1.1}
 If $x_{p}$ is a particular solution of \eqref{LE}, than any other solution $x$ of the equation is the sum between a certain solution $x_{o}$ of the homogeneous equation and $x_{p}$, meaning: $$x=x_{o}+x_{p}.$$ Reciprocically, any solution $x_{o}$ of the homogeneous equation is the difference between a certain solution $x$ of \eqref{LE} and $x_{p}$.
\end{theorem}
The theorem sustains that for solving a \eqref{LE}, we have to go through two stages:
\begin{enumerate}
 \item to solve the associated homogeneous equation;
 \item to determine a particular solution of \eqref{LE}.
\end{enumerate}

\subsection{Examples}
$1)$ $x'+x\tan t=\frac{1}{\cos{t}}$, $t\in (-\frac{\pi}{2},\frac{\pi}{2})$\\\\
\underline{Solution}: For solving this equation, we will use the result from \ref{1.2.1.1}. 
The associated homogeneous equation is: $$x{o}'=-x_{o}\tan t.$$ Separating the variables, we get: $$\frac{dx_{o}}{x_{o}}=-\tan t dt.$$ By integration, we obtain: $$\ln{x_{o}}=\ln{\cos{t}}+c_{1},c_{1}\in\R \Leftrightarrow$$
$$x_{o}=c\cos{t}, c\in\R.$$ 
The particular solution for the given linear differential equation of first order is:
$$x_{p}=c(t)\cos{t}.$$ By replacing in the given equation, we obtain:
$$c'(t)\cos{t}-c(t)\sin{t}+c(t)\tan t\cos{t}=\frac{1}{\cos{t}}\Leftrightarrow$$
$$c'(t)\cos{t}=\frac{1}{\cos{t}}\Leftrightarrow$$
$$c'(t)=\frac{1}{\cos^{2}{t}}\Leftrightarrow$$
$$c(t)=\tan t.$$
Meaning that the particular solution is:
$$x_{p}=\tan t \cos{t} \Leftrightarrow x_{p}=\sin{t}.$$
Hence, the solution is:
$$x=x_{p}+x_{o} \Leftrightarrow x=\sin{t}+c\cos{t}.$$
$2)$ $\begin{cases}
       x'+x=e^{2t}\\
       x(0)=1
      \end{cases}$\\\\
      \underline{Solution:} The associated homogeneous equation is: $$x_{o}'=-x_{o}.$$ Separating the variables, we get: $$\frac{dx_{o}}{x_{o}}=-dt.$$ By integration, we obtain: $$\ln{x_{o}}=-t+c_{1},c_{1}\in\R\Leftrightarrow$$ 
      $$x_{o}=ce^{-t},c\in\R.$$ Hence, the particular solution for the given linear differential quation of first order has the following form: $$x_{p}=c(t)e^{-t}.$$ Further, replacing in the given equation we get: $$c'(t)e^{-t}-e^{-t}c(t)+e^{-t}c(t)=e^{2t}\Leftrightarrow$$
      $$c'(t)=e^{3t}\Leftrightarrow c(t)=\frac{1}{3}e^{3t}.$$
      Thus, the general solution has the following form:
      $$x=ce^{-t}+\frac{1}{3}e^{2t}, c\in \R.$$
      Then, by attaching the Cauchy condition, we get that the constant $c=\frac{2}{3}$, which means that the solution for the given Cauchy problem is: $$x=\frac{2}{3}e^{-t}+\frac{1}{3}e^{2t}.$$


\section{Linear Differential Systems}
\subsection{The general form of a linear differential system}
Many evolutive processes from the real world can not be described by only one variable. Therefore, for two or more variables, we must consider a system 
of two or more differential equations. In the following chapter, we will consider differential systems of the first order:
\begin{equation}
\begin{cases}
 x'=f(t,x,y)\\ 
 y'=g(t,x,y)\\
\end{cases}
 \label{DS}\tag{DS}
\end{equation}

where $f$,$g$ are given functions and the unknowns are the functions $x,y$ of variable $t$. \\

\begin{definition} 
A solution for \eqref{DS} is a pair $(x,y)\in C^{1}(J)$, where $J\subseteq \R$, which satisfy on $J$ the two equations from \eqref{DS}, for 
any $t\in J$. 
\end{definition}
 
\eqref{DS} is linear if functions $f$ and $g$ depend affinely on $x$ and $y$. Then \eqref{DS} has the following form:
\begin{equation}
 \begin{cases}
  x'=a_{11}(t)x+a_{12}(t)y+b_{1}(t)\\
  y'=a_{21}(t)x+a_{22}(t)y+b_{2}(t)\\
 \end{cases}
\label{DS*}\tag{DS*}
\end{equation}

Coefficients $a_{ij}$ and free terms $b_{i}$ are alleged to be continuous functions on an interval $J$. If, in particular, coefficients $a_{ij}$
are constants, we say that the linear system is with constant coefficients. If $b_{i}=0$, we say that the system is homogeneous. If both situations
take place, the system is linear and homogeneous, with constant coefficients.

\subsection{Matrix analysis theory}

Let us define $\mathcal{M}_{nm}(\mathbb{K})$ the set of matrices with n rows and m columns, with elements from the field $\mathbb{K} (\R$ or $\mathbb{C})$. It is known that $(\mathcal{M}_{nm}(\mathbb{K}), +, \cdot, \R)$ is a linear space of dimension $n\cdot m$. It can be organized as a normalized space using the following norm:
\begin{equation*}
 \rVert A \rVert = \bigg( \sum_{i,j=1}^{n} a_{ij}^{2} \bigg)^\frac{1}{2}
\end{equation*}

Then $(\mathcal{M}_{nm}(\mathbb{K}), \rVert \cdot \rVert)$ is a Banach space. The defined norm has the following properties on the Banach space presented earlier:
\begin{enumerate}
  \item $\rVert A+B \rVert \leq \rVert A \rVert + \rVert B \rVert$
  \item $\rVert \lambda A \rVert = |\lambda|\rVert A \rVert$
  \item $\rVert Ax\rVert_{\R ^{n}} = \rVert A \rVert \rVert x \rVert _{\R ^{n}}$
  \item $\rVert A \cdot B \rVert \leq \rVert A \rVert \cdot \rVert B \rVert$
 \end{enumerate}
Next, let $M\in\mathcal{M}_{nn}(\mathbb{K})$. Then:
\begin{equation}
 e^{M}=\sum_{k\geq0} \frac{1}{k!} M^{k} \label{3.1} \tag{3.1}
\end{equation}
\begin{proof}
 Let $$S_{n}=\sum_{k=0}^{n}\frac{1}{k!}M^{k}$$be the partial sum of serie \eqref{3.1}. Next, we prove that $S_{n}$ is a Cauchy sequence in the Banach space $(\mathcal{M}_{nm}(\mathbb{K}), \rVert \cdot \rVert)$. 
 \begin{equation*}
  \rVert S_{n+p}-S_{n}\rVert=\rVert\frac{1}{(n+1!)} A^{n+1}+...+\frac{1}{(n+p!)} A^{n+p}\rVert
  \end{equation*}
  \begin{equation*}
   \leq \frac{1}{(n+1)!}\rVert A^{n+1}\rVert+...+\frac{1}{(n+p)!}\rVert A^{n+p}\rVert=|a_{n+p}-a_{n}|
  \end{equation*}
where $$a_{n}=\sum_{k=0}^{n}\frac{1}{k!}\rVert M \rVert ^{k}.$$\\
Due to the fact that $$\sum_{k\geq 0} \frac{1}{k!}x^{k}$$ is a convergent series and the sum of it is equal to $e^{x}$, $\forall x\in \R$ $\Rightarrow$ $$\sum_{k\geq 0}\frac{1}{k!}\rVert M \rVert ^{k}$$ is convergent, therefore $a_{n}$ is convergent, which means that $a_{n}$ is Cauchy $\Rightarrow$ $\forall \varepsilon > 0$,  $\exists n(\varepsilon) \in \mathbb{N}$ so that $$\rVert S_{n+p} - S_{n} \rVert \leq \varepsilon$$ $\forall n\geq n(\varepsilon)$, $ \forall p\in \mathbb{N}$ $\Rightarrow$ $(S_{n})$ is a Cauchy sequence $\Rightarrow$ the existence of \eqref{3.1} is proved.


\end{proof}





\subsection{Existence and uniqueness theorems}

Let us consider the system:
\begin{equation}
 \begin{cases}
  u'=A(t)u+B(t)\\
u(t_{0})=u_{0}
 \end{cases}\label{Sys1}\tag{Sys1}
\end{equation}

where $t\in J=[t_{0}-a,t_{0}+a], a>0$ $t_{0}\in J$ and $u_{0}\in\R^{2}$. \newline
Regarding the existence and uniqueness of the solution of the previous system, we present the following result:
\begin{theorem}
 Considering \eqref{Sys1}, we assume that $A\in C(J,\mathcal{M}_{2}(\R))$, $B\in C(J,\R^{2})$. Then, there exists a unique 
 solution $u^{*}\in C^{1}(J,\R^{2})$.
\end{theorem}
\begin{proof}
 We will use the following Lemma:
 \begin{lemma}
  The solution $u^{*}$ is equivalent to the following system of integral equations:
  \begin{equation}
   u(t)=\int_{t_0}^{t}\bigg[ A(s)u(s)+B(s)\bigg] ds+u_{0} \label{IntSol}\tag{IntSol}
  \end{equation}
 \end{lemma}
\begin{proof}
  \textquotedblleft $\Rightarrow$ \textquotedblright
  If $u$ satisfies \eqref{Sys1}, then by integrating from $t_{0}$ to $t\in J$, we get:
  \begin{equation*}
   u(t)-u(t_{0})=\int_{t_0}^{t}\bigg[ A(s)u(s)+B(s)\bigg] ds
  \end{equation*}
$u(t_{0})=u_{0}$ $\Rightarrow$ \eqref{IntSol}.\newline
\textquotedblleft$\Rightarrow $\textquotedblright
  Let $u$ be a solution of \eqref{IntSol}. Then $u'(t)=A(t)u+B(t)$. Since the right side is continuous, we obtain that $u\in C^{1}(J,\R)$.
  Moreover, $u(t_{0})=u_0$.
  The lemma is proved.
\end{proof}
Resuming the proof of the theorem, let us denote $A:C(J,\R^{2})\rightarrow C(J,\R^{2})$, $u\longmapsto Au$, where:
$Au(t):=\int_{t_0}^{t}\bigg[ A(s)u(s)+B(s)\bigg] ds+u_{0}$

\textquotedblleft\eqref{IntSol} $\Leftrightarrow$ $u=Au$\textquotedblright

We consider on $C(J,\R^2)$ the Bielecki norm:
\begin{equation*}
\Arrowvert u \Arrowvert_{B} = max_{t\in J}(\Arrowvert u \Arrowvert_{\R^2} e^{-\tau\arrowvert t-t_{0}\arrowvert}), \tau>0
\end{equation*}
$(C(J,\R^{2}),\Arrowvert\ldotp\Arrowvert)$ is a Banach space.\newline
Then we have that $\Arrowvert Au-Av\Arrowvert_{B}\leq L_{A} \Arrowvert u-v \Arrowvert_{B}, \forall u,v \in C(J,\R^{2}, L_{A} \in (0,1))$.\newline
For $t\geq t_{0}$:\\


 $$\Arrowvert Au(t)-Av(t) \Arrowvert _ {\R^{2}} = \Arrowvert \int_{t_{0}}^{t} A(s)(u(s)-v(s)) ds \Arrowvert$$ 
 $$\leq \int_{t_{0}}^{t} \Arrowvert A(s)(u(s)-v(s)) \Arrowvert ds$$ 
 $$\leq \int_{t_{0}}^{t} \Arrowvert A(s) \Arrowvert _ {\M(\R^{2})} \Arrowvert u(s)-v(s) \Arrowvert _ {\R^{2}}ds$$
 $$\leq M_{A} \int_{t_{0}}^{t} \Arrowvert u(s)-v(s) \Arrowvert e^{-\tau(s-t_{0})}e^{\tau(s-t_{0})} ds$$
 $$\leq \int_{t_{0}}^{t} \smash{\displaystyle\max_{(s \in J)}} (\Arrowvert u(s)-v(s)\Arrowvert  e^{-\tau(s-t_{0})})  e^{\tau(s-t_{0})} ds $$
 $$\leq M_{A} \Arrowvert u-v \Arrowvert _ {B} \frac{1}{\tau}(e^{\tau(t-t_{0})}-1)$$
 $$\leq \frac{M_{A}}{\tau} \Arrowvert u-v \Arrowvert _ {B} e^{\tau(t-t_{0})}$$ 
 $$\Rightarrow \Arrowvert Au-Av \Arrowvert \leq \frac{M_{A}}{\tau} \Arrowvert u-v \Arrowvert _ {B}.$$ Let $L_{A}=\frac{M_{A}}{\tau}$ such as $\tau > M_{A}$. Then $L_{A}<1$.



\end{proof}






\subsection{Representations of the solution}

Let us remark that \eqref{DS} can be written as a single vectorial equation:
\begin{equation}
 u'=F(t,u) \label{VDS}\tag{VDS}
\end{equation}
where $u$ and $F$ are vectorials, with two real components, more exactly column matrix:\newline
\begin{equation*}
u =
 \begin{bmatrix}
  x\\
  y\\
 \end{bmatrix}
, \quad F(t,u) =
\begin{bmatrix}
 f(t,x,y)\\
 g(t,x,y)\\
\end{bmatrix}
\end{equation*}
\newline

The condition for the Cauchy Problem of the system can be written:
\begin{equation*}
 u(t_{0})=u_{0},\\
 u_{0}= \begin{bmatrix}
         x_{0}\\
         y_{0}
        \end{bmatrix}
\end{equation*}
\newline
Also, \eqref{DS*} can be written:
\begin{equation}
 u'=A(t)u+B(t) \label{MDS}\tag{MDS}
\end{equation}
where 
\begin{equation*}
 A(t)=\begin{bmatrix}
       a_{11}(t) & a_{12}(t)\\
       a_{21}(t) & a_{22}(t)\\
      \end{bmatrix}
\quad
B(t)=\begin{bmatrix}
      b_{1}(t)\\
      b_{2}(t)
     \end{bmatrix}
\end{equation*}

\begin{theorem}[of representing the solutions of linear systems]
 Let $A\in C(J,\mathcal{M_{2}}))$ and $B\in(J,R^{2})$. Then the solutions of the linear system \eqref{MDS} are defined by the formula 
 \begin{equation}\label{1.2}
  u=e^{\int_{t_0}^{t} A(\sigma)d\sigma}C+\int_{t_0}^{t}e^{\int_{s}^{t} A(\sigma)d\sigma}B(s)ds
 \end{equation}
where $C=\begin{bmatrix}C_{1}\\ C_{2}\end{bmatrix}$ and $C_{1}, C_{2}\in \R.$

\end{theorem}

\begin{theorem}[of existence, uniqueness and representation of the solution]
 Let $A\in C(J,M_{2}(\R)), B\in C(J,\R), t_{0}\in J and u_{0}\in \R^{2}$. Then the Cauchy Problem has a unique solution 
 defined on $J$, given by the formula:
 \begin{equation}\label{1.3}
  u=e^{\int_{t_0}^{t} A(\sigma)d\sigma}u_{0}+\int_{t_0}^{t}e^{\int_{s}^{t} A(\sigma)d\sigma}B(s)ds
 \end{equation}

\end{theorem}

\begin{theorem}[the structure of the set of solutions]

(a) The set of solutions of a bidimensional linear and homogeneous system is a linear bidimensional space.\\
(b) If $u_{p}$ is a particular solution of a linear non-homogeneous system \eqref{MDS}, then any other solution $u$ of the system \eqref{MDS}
is the sum between the solution of the homogeneous system ($u_{o}$) with the particular solution $u_{p}$:
\begin{equation*}
 u=u_{o}+u_{p}
\end{equation*}
\end{theorem}

\begin{definition}
 A matrix in which the columns are the linearly independent solutions of the homogeneous system is called fundamental matrix of the system.
\end{definition}
 
 \begin{lemma}\label{1.3.4.4.}
  (a) Any fundamental matrix is unsingular for any $t \in J$.\\
  (b) Any fundamental matrix $U(t)$ satisfies the differential matricial equation:
  \begin{equation*}
   U'(t)=A(t)U(t)
  \end{equation*}

 \end{lemma}
\subsection{Representation with fundamental matrix}
In this paragraph, let us submit the possibility of representing the solutions of the non-homogeneous system in terms of the fundamental matrix $U(t)$, of which purpose is to replace the matrix $e^{\int_{t_{0}}^{t} A(\sigma)d\sigma}$ from \eqref{1.2}.\\
Firstly, let $$u_{p}=U(t)C(t)$$ be a particular solution of the non-homogeneous system, where the vectorial function $$C(t)=
\begin{bmatrix}
 C_{1}(t)\\
 C_{2}(t)
\end{bmatrix}$$ is to be determined with the condition that $u_{p}$ satisfies the given system. Hence
$$u'_{p}=U'(t)C(t)U(t)C'(t)$$
and by replacing we find that
$$U'(t)C(t)+U(t)C'(t)=A(t)U(t)C(t)+B(t).$$
Point $b)$ from lemma \ref{1.3.4.4.} guarantees that
$$U'(t)=A(t)U(t).$$
Thus $U(t)C'(t)=B(t)$, which means that $C'(t)=U^{-1}(t)B(t)$. Then, according to point $a)$ from \ref{1.3.4.4.}, matrix $U(t)$ is invertible. Let us choose
$$C(t)=\int_{t_0}^{t} U^{-1}(s)B(s)ds$$
and so we get a particular solution of the non-homogeneous system:
$$u_{p}=\int_{t_0}^{t} U(t)U^{-1}(s)B(s)ds.$$
Thus, an equivalent of \eqref{1.2} is:
\begin{equation}\label{1.4}
 u=U(t)C+\int_{t_0}^{t} U(t)U^{-1}(s)B(s)ds.
\end{equation}
The analogue of \eqref{1.3} results immediately:
\begin{equation}\label{1.5}
 u=U(t)U^{-1}(t_{0})u_{0}+\int_{t_0}^{t} U(t)U^{-1}(s)B(s)ds.
\end{equation}

Hence, we can present the following theorem:
\begin{theorem}[of representation with fundamental matrix]\label{1.3.5.1}
 If $U(t)$ is a fundamental matrix of \eqref{MDS}, then:
 \begin{enumerate}[(i)]
  \item The solutions of the homogeneous system are the functions $u_{o}=U(t)C$, where $C$ is a random vector from $\R^{2}$;
  \item The solutions of the non-homogeneous system are the functions defined by \eqref{1.4}, where $C\in\R^{2}$;
  \item The solution of the Cauchy problem for \eqref{Sys1} is the function defined by formula \eqref{1.5}.
 \end{enumerate}
\end{theorem}
According to \ref{1.3.5.1}, solving a linear system depends on finding a fundamental matrix. Generally, this is not possible, but for the systems with constant coefficients is possible.


\subsection{Linear systems with constant coefficients}

In this paragraph, we consider the system \eqref{DS*}, where the coefficients $a_{ij}(i,j=1,2)$ are constant, and $b_{1},b_{2}\in C(J)$. By using matrices, we can rewrite the system as:
$$u'=Au+B(t),$$
where
$$u=\begin{bmatrix}
     x\\
     y\\
    \end{bmatrix}, 
A=\begin{bmatrix}
   a_{11} & a_{12}\\
   a_{21} & a_{22}\\
  \end{bmatrix},
B=\begin{bmatrix}
   b_{1}(t)\\
   b_{2}(t)\\
  \end{bmatrix}.$$

Due to the fact that all the previous results stay valid, the solutions of the system have the following form:
$$u=u_{o}+u_{p}.$$
The explicit form of the solution is:
\begin{equation*}
 u=e^{(t-t_{0})\cdot A}\cdot C+\int_{t_0}^{t} e^{(t-s)\cdot A}B(s) ds,
\end{equation*}
where the constant vector $C$ is random. Also, the Cauchy problem, with $u(t_{0})=u_{0}$ as the initial condition admits only one solution, which is
\begin{equation}\label{1.6}
  u=e^{(t-t_{0})\cdot A}\cdot u_{0}+\int_{t_0}^{t} e^{(t-s)\cdot A}B(s) ds
\end{equation}
If by the replacement of $e^{(t-t_{0})\cdot A}$ it is considered another fundamental matrix $U(t)$, then the solutions of the system and also for the Cauchy problem are given by formulas \eqref{1.4} and \eqref{1.5}. The question of how we can determinate the fundamental matrix and how we can directly solve the system still remains.\\
For this, let us search for solutions for the associated homogeneous system based on the following form:
$$u=e^{rt}V,$$
where $r\in\R$ and $V=\begin{bmatrix} v_{1}\\v_{2}\\ \end{bmatrix} \in \R^{2}$ are determined with the condition that $u$ satisfies the homogeneous system. Obviously, $V\neq 0$. By replacing in the homogeneous system, we get:
$$re^{rt}V=A(e^{rt}V)=e^{rt}AV.$$
By simplifying with $e^{rt}$, we obtain:
\begin{equation}\label{1.7}(A-rI)V=0.\end{equation}
As $V\neq 0$, we conclude that $r$ is an eagen value of matrix $A$, and $V$ is an eagen vector associated to this value. Eagen values are determined with the condition that the algebraic homogeneous system \eqref{1.7} admits solutions unequal to $0$, meaning from equation:
\begin{equation}\label{1.8}
 det(A-rI)=0.
\end{equation}
This equation is named the characteristic equation of the system and is a second grade polynomial. It can be written:
\begin{equation}
 \begin{vmatrix}\label{det}
 a_{11}-r & a_{12}\\
 a_{21} & a_{22}-r\\
\end{vmatrix}
=0,
\end{equation}
where, by solving the determinant, we obtain:
$$r^{2}-(a_{11}+a_{22})r+a_{11}a_{22}-a_{12}a_{21}=0,$$
meaning
$$r^{2}-(tr A)r+det A=0.$$
Here, $$tr A=\sum_{i=0}^{n}a_{ii}$$ is the trace of the matrix. Considering how the roots of the characteristic equations might be, we distinguish the following cases:
\subsubsection{Case of real and distinct roots}
Let $r_{1},r_{2}$ be the roots of the characteristic equation, which are presumed to be real and distinct.
For each one, we choose a non-null solution of system \eqref{1.7}. Let them be $V_{1},V_{2}$. Meaning that we obtained two solutions for the homogeneous system:
$$ u_{1}=e^{r_{1}t}V_{1},\quad u_{2}=e^{r_{2}t}V_{2}.$$
As $r_{1}\neq r_{2}$, they are linear independent. Matrix $U(t)$, with columns $u_{1},u_{2}$ thus determined, is a fundamental matrix.

\subsubsection{Case of equal roots}
Let us presume that the roots of the characteristic equation are equal. Then $r:=r_{1}=r_{2}=\frac{tr A}{2}$. A solution of the system can be determined similarly to the previous case, of form $u_{1}=e^{rt}V$, where $V$ is a non-null solution of the algebraic homogeneous system \eqref{1.7}. A second solution $u_{2}$, linear independent of $u_{1}$, is searched by the form $u_{2}=e^{rt}(tV+W)$, with $V$ being the previous, and $W$ being vector which is obtained with the condition that verifies the system. We have:
$$ u'_{2}=re^{rt}(tV+W)+e^{rt}V$$
meaning that $u_{2}$ is a solution if
$$re^{rt}(tV+W)+e^{rt}V=e^{rt}A(tV+W).$$
By simplifying with $e^{rt}$ and by reducing the equal terms, we obtain the following algebraic linear and non-homogeneous system:
$$(A-rI)W=V.$$
This system is compatible and so we can choose a solution $W$ of it.

\subsubsection{Case of complex roots}
Let us presume that the roots of the characteristic equation are complex, being them $\alpha \pm \beta i$. Considering one of them, for example $\alpha + \beta i$ and by proceeding like in the case of real and distinct roots, let us determine a solution of the system, this time complex:

 $$u=e^{rt}V=e^{(\alpha+\beta i)t}(V_{1}+iV_{2})=
 e^{\alpha t}(\cos{\beta t}+i\sin{\beta t})(V_{1}+iV_{2})=$$
 $$=e^{\alpha t}[V_{1}\cos{\beta t}-V_{2}\sin{\beta t}+i(V_{1}\sin{\beta t}+V_{2}\cos{\beta t})].$$

where $V_{1},V_{2}$ represents the column vector of the real parts, respectively the coefficients of the imaginary parts of $V$, meaning $V=V_{1}+iV_{2}$ and $V_{1},V_{2} \in \R^{2}$. 
With the system being linear, homogeneous and with real coefficients, at once with a complex solution $u$, admits as solutions the conjugate function $\bar{u}$, as well as any linear combination of theirs with complex coefficients, particularly the real functions:
$$u_{1}:=Re (u)=\frac{1}{2}(u+\bar{u})=e^{\alpha t}(V_{1}\cos{\beta t}-V_{2}\sin{\beta t}),$$
$$u_{2}:=Im (u)=\frac{1}{2i}(u-\bar{u})=e^{\alpha t}(V_{1}\sin{\beta t}+V_{2}\cos{\beta t}).$$
 
 \subsection{Examples}
 $1)$ 
 $U'=AU$, where $A=\begin{bmatrix}
                    0 && 4\\
                    5 && 1\\
                   \end{bmatrix}$, $U=\begin{bmatrix} u_{1} \\ u_{2}\end{bmatrix}$.
                   
 \underline{Solution:}
First, let us attach the characteristic equation: $r^{2}-(tr(A))r+det(A)=0$. In our case, $tr(A)=1$ and $det(A)=-20$, meaning that the equation becomes: $r^{2}-r-20=0$. By solving the equation, we get the following roots: $r=5$ and $r=-4$. 
Let us consider the first case, where $r=5$. Next, we need to determine an eigenvector $V=\begin{bmatrix}
                                                                                           v_{1}\\
                                                                                           v_{2}
                                                                                          \end{bmatrix}$,by solving $(A-rI)V=0$. A convienent eigenvector would be $V=\begin{bmatrix}
                                                                                          4\\
                                                                                          -5\\\end{bmatrix}$
Hence, the solution is:
$$ U_{1}=e^{rt}V=e^{5t}\begin{bmatrix}4\\-5\\\end{bmatrix}=\begin{bmatrix} 4e^{5t} \\ -5e^{5t} \end{bmatrix}.$$
                                                            
                                                            
Next, we consider the case where $r=-4$. Thus, an eigenvector would be $V=\begin{bmatrix} 1 \\ -1 \end{bmatrix}$. Hence, the solution is:
$$U_{2}=e^{-4t}\begin{bmatrix} 1 \\ -1 \end{bmatrix}=\begin{bmatrix} e^{-4t}\\-e^{-4t}\end{bmatrix}.$$

Then, the fundamental matrix of the solutions of the system is:

$$U=c_{1}U_{1}+c_{2}U_{2},$$
where $c_{1},c_{2} \in \R$.

                                                                                    
$2)$ $U'=AU$, where $A=\begin{bmatrix}
                    -3 && -8\\
                    2 && 5\\
                   \end{bmatrix}$, $U=\begin{bmatrix} u_{1} \\ u_{2}\end{bmatrix}$.\\
\underline{Solution:}
By attaching the characteristic equation, we get that $r=1$ is a solution of the equation of multiplicity 2. We are in the case of equal roots. Next, by solving the equation $(A-rI)V=0$, we get that $V=\begin{bmatrix} -2\\1\end{bmatrix}$ is an eigenvector of the given equation. By solving $(A-rI)W=V$, we get $W=\begin{bmatrix} 1\\ -\frac{2}{8} \end{bmatrix}$. Then:
$$ U_{1}=e^{t}\begin{bmatrix} -2\\1\end{bmatrix}$$ and $$U_{2}=e^{t}\begin{bmatrix} -2t+1\\t-\frac{2}{8} \end{bmatrix}.$$
Hence, the fundamental matrix of the solutions has is $U=c_1U_{1}+c_{2}U_{2}$, where $c_{1},c_{2} \in \R$.

$3)$ $U'=AU$, where $A=\begin{bmatrix}
                    5 && 5\\
                    -4 && 3\\
                   \end{bmatrix}$, $U=\begin{bmatrix} u_{1} \\ u_{2}\end{bmatrix}$.\\
    \underline{Solution:}
    By solving the characteristic equation, we denote that we are in the case of complex roots, where $r=1\pm2i$. Next, we find that $V=\begin{bmatrix} 1 \\ -\frac{4}{5}+i\frac{2}{5} \end{bmatrix}$ is a convienient eigenvector for the case. The solution is 
    $$ U=e^{(1+2i)t}\begin{bmatrix} 1 \\ -\frac{4}{5}+i\frac{2}{5} \end{bmatrix} 
    = e^{t}(\cos{2t}+i\sin{2t})\bigg( \begin{bmatrix} 1\\ -\frac{4}{5}\end{bmatrix} + \begin{bmatrix} 0\\ \frac{2}{5}\end{bmatrix} i \bigg).$$
    By separating the real part and the imaginary part, we get two real solutions:
    $$U_{1}=e^{t}\bigg( \cos{2t}  \begin{bmatrix} 1\\ -\frac{4}{5}\end{bmatrix} - \sin{2t} \begin{bmatrix} 0\\ \frac{2}{5}\end{bmatrix} \bigg) $$ and
    $$ U_{2}=e^{t}\bigg( \cos{2t} \begin{bmatrix} 0\\ \frac{2}{5}\end{bmatrix} + \sin{2t} \begin{bmatrix} 1\\ -\frac{4}{5}\end{bmatrix} \bigg).$$

\section{Dynamic systems}
\subsection{The dynamic of an operator}
 Let $(X,d)$ be a complete metric space and $f:X\rightarrow X$ an operator. If $x\in X$, then $f(x)$ will be named the state of $x$ through $f$. The sequence of successive aproximations $$x,f(x),f^{2}(x),...$$ represents the states of $x$ through the iterations of $f$. Space $X$ will be named the space of states. Set $$\{x,f(x),f^{2}(x),...,f^{n}(x),...\}$$ will be called the orbit of $x$ through $f$. If $x\in X$ is a fixed point of $f$, then $f^{n}(x)=x$. For this reason, the fixed points of f will be named equilibrium states or stationary positions. The pair $(X,f)$ will be refered to as a dynamic.
 The central matter of the theory of dynamic systems consists in the study of the movements of a dynamic system. For example, we question the study of limit points of the sequence of successive aproximations.
 Let $x_{0}\in X$. A state $\xstar \in X$ is called an $\omega$-limit state of $x$ if exists $n_{k}\rightarrow \infty$ such that $f^{n_{k}}(x_{0})\rightarrow \xstar$. $\omega(x_{0})$ represents the set of $\omega$-limit states of $x_{0}$ in relation with operator $f$.
 \paragraph{Example} Let us consider the dynamic system $(\R,f)$ where $f(x)=x^{3}$. next, we study the $\omega$-limit states of $f$. In this case we have:
 \begin{enumerate}[i)]
  \item If $|x|>1$ then $f^{n}(x)=x^{3^{n}}\rightarrow \infty$ meaning $\omega(x)=\emptyset$;
  \item If $|x|<1$ then $f^{n}(x)=x^{3^{n}}\rightarrow 0$ meaning $\omega(x)={0}$;
  \item When $f^{n}(1)=1^{3^{n}}\rightarrow 1$ then $O(f;1)={1}$ and so $\omega(1)={1}$;
  \item When $f^{n}(-1)=(-1)^{3^{n}}\rightarrow -1$ then $O(f;-1)={-1}$ and so $\omega(-1)={-1}$.
 \end{enumerate}

\subsection{The notion of a dynamic system}
Let $(X,d)$ be a metric space. Let $(G,+,\tau)$ be a topologic group, meaning that:
\begin{enumerate}
 \item $(G,+)$ is a group;
 \item $(G,\tau)$ is a separated topologic space;
 \item operators:
 $$+: G\times G\rightarrow G, (t_{1},t_{2})\rightarrow t_{1}+t_{2}$$
 $$-:G\rightarrow G, t\rightarrow -t.$$ are continuous.
\end{enumerate}
Let $\varphi:G\times X\rightarrow X$ be an operator.
\begin{definition}
 The triplet $(X,G,\varphi)$ is named a dynamic system if:
 \begin{enumerate}[i)]
  \item $\varphi(0,x)=x,\forall x\in X$
  \item $\varphi(t,\varphi(s,x))=\varphi(t+s,x),\forall t,s \in G, \forall x\in X$
 \end{enumerate}
\end{definition}
If $G=\mathbb{Z}$, then the system is called discrete. If $G=\R$, then the system is called continuous.
Space $X$ is called the phases space or the states space. Operator $\varphi(t,\cdot):X\rightarrow X, t\in G$ is called the transition operator. Operator $\varphi(\cdot,x):G\rightarrow X, x\in X$ is called the movement of x in regard with the dynamic system $(X,G,\varphi)$. The set $\varphi(G,X)$ is called the trajectory of $x$ or the orbit of $x$.
In the next paragraph, we presume $G$ to be an abelian group.
Considering the axioms of the dynamic system, we have the following results.
\begin{theorem}
 If $(X,G,\varphi)$ is a dynamic system, then $\varphi(t,\cdot):X\rightarrow X$ is a topological isomorphism, for all $t$ in $G$.
\end{theorem}
\begin{proof}
 We observe that $$\varphi(-t,\cdot)\circ \varphi(t,\cdot)=\varphi(t,\cdot) \circ \varphi (-t,\cdot)=1_{x},$$ for all $t\in G$. So $\varphi(t,\cdot)$ is a bijection and $(\varphi(t,\cdot))^{-1}=\varphi(-t,\cdot)$. Knowing that $\varphi$ is continuous and that $G$ is a topological group, results that operators $\varphi(t,\cdot)$ and $\varphi(-t,\cdot)$ are continuous. So $\varphi(t,\cdot)$ is a topological isomorphism for all $t\in G$.
\end{proof}

\begin{theorem}
 The set of transition operators $\{\varphi(t,\cdot)|t\in G\}$ forms an abelian group in relation to operator composition operation.
\end{theorem}

\begin{proof}
 Let $T:=\{\varphi(t,\cdot)|t\in G\}$. Let $\varphi(t,\cdot), \varphi(s,\cdot)\in T$. Then $\varphi(t,\cdot)\circ \varphi(s,\cdot)=\varphi(t+s,\cdot)\in T$. So $T$ is closed in relation to composition operation. The asociativity and commutativity properties can be easily proved. $\varphi(0,\cdot)=1_{x}$ is the unit element and $\varphi(-t,\cdot)$ is the reserve element of $\varphi(t,\cdot), t\in G$.
\end{proof}

\subsection{Examples}
\subsubsection{Dynamic systems defined by a topological isomorphism}
Let $(X,d)$ be a metric space and $f:X\rightarrow X$ a topological isomorphism. Let $$\varphi:\mathbb{Z}\times X\rightarrow X, (t,x)\rightarrow f^{t}(x).$$ In these conditions, triplet $(X,\mathbb{Z},\varphi)$ is a dynamic system. We remind that $f^{0}=1_{x}$, $f^{t}$, for $t\in\mathbb{Z}$, $t>0$, is the number $t$ iteration of $f$, and $f^{-t}$ is the number $t$ iteration of $f^{-1}$. It is easy to prove that the axioms of the dynamic systems are valid in this case. This system will be called the dynamic system generated by $f$ or the dynamic system presented through a topological isomorphism or the dynamic system defined by isomorphism $f$.
\subsubsection{Dynamic systems defined by systems of differential equations}
Firstly, let us consider a system of differential equations with constant coefficients 
\begin{equation}\label{1.10}
 x'=Ax, A\in \mathcal{M}_{n}(\R)
\end{equation}
We have observer that the flux of system \eqref{1.10} is given by $$\varphi:\R\times\R^{n}\rightarrow\R^{n},(t,\eta)\rightarrow e^{tA}\eta.$$ The flux of a system of form $x'=Ax+B$ is the function $\varphi:[a,b]\times\R^{n}\rightarrow\R^{n},(t,\eta)\rightarrow x(t;t_{0},\eta)$.
\begin{theorem}
 The flux $\varphi(t,\eta)=e^{tA}\eta$ (the case where $A$ is a constant matrix) satisfies the following statements:
 \begin{enumerate}
  \item $\varphi(0,\eta)=\eta,\forall \eta\in\R^{n}$
  \item $\varphi(s+t,\eta)=\varphi(t,\varphi(s,\eta)),\forall t,s\in\R,\forall \eta\in\R^{n}$
  \item $\varphi(t,\varphi(-t,\eta))=\varphi(-t,\varphi(t,\eta))=\eta,\forall \eta\in\R^{n},\forall t\in\R$
  \item $\varphi\in C^{\infty}(\R\times\R^{n},\R^{n})$.
 \end{enumerate}

\end{theorem}
From the stated theorem results that $(\R^{n},\R,\varphi)$ is a dynamic system. More generally, let us consider the autonomous system \begin{equation}\label{1.11}
x'=f(x)                                                                                                                                       
                                                                                                                                \end{equation}
where $f\in C(\R^{n},\R)$. We presume that for all $\eta\in\R^{n}$, \eqref{1.11} has in $C^{1}(\R,\R^{n})$ an unique solution, which satisfies $$x(0)=\eta.$$ We note the relation with $\varphi(\cdot,\eta)$. Function $\varphi:\R\times\R^{n}\rightarrow \R^{n}$, $(t,\eta)\rightarrow\varphi(t,\eta)$ is by definition the flux of \eqref{1.11}. $(\R^{n},\R,\varphi)$ is a dynamic system.

\subsection{Fixed points}
Let $(X,G,\varphi)$ a dynamic system. A point $x_{0}\in X$ is called a fixed point of system $(X,G,\varphi)$ if $$\varphi(t,x_{0})=x_{0},\forall t\in G.$$
It can be easily proved that the following theorem is valid:
\begin{theorem}
 Let us consider $(X,G,\varphi)$ a dynamic system. Then we have:
 \begin{enumerate}
  \item $\varphi(G,x_{0})=\{x_{0}\} \Leftrightarrow x_{0}$ is a fixed point of the dynamic system;
  \item the set of fixed points of the dynamic system is given by: $$\cap_{t\in G} F_{\varphi(t,\cdot)}$$
  \item the set of fixed points is a closed set.
 \end{enumerate}

\end{theorem}
Let us consider further a dynamic system presented through a topological isomorphism $f:X\rightarrow X$, where $(X,d)$ is a metric space. In this case, $\varphi(t,x)=f^{t}(x).$ So $x_{0}\in X$ is a fixed point of the dynamic system only if $x_{0}\in \cap_{t\in\mathbb{Z}}F_{f^{t}}$. But $\cap_{t\in\mathbb{Z}}F_{f^{t}}=F_{f}$, denoting that the fixed points of the dynamic system defined by $f$ are the fixed points of $f$.
Let us consider a dynamic system defined by the autonomous system
\begin{equation}\label{1.12}
 x'=f(x)
\end{equation}
where $f\in C^{1}(\R^{n},\R^{n})$. Let us presume that all the saturated solutions are defined on $\R$. In this case, $\varphi(\cdot,\eta)$ is the unique solution of system \eqref{1.12} which satisfies the condition
\begin{equation}
 x(0)=\eta. \label{1.13}
\end{equation}
Point $\eta\in\R^{n}$ is a fixed point for this dynamic system, if $$\varphi(t,\eta)=\eta,\forall t\in\R.$$
From \eqref{1.12} results that $\eta$ is a fixed point for the dynamic system generated by \eqref{1.12}, only if $f(\eta)=0$. So the set of fixed points is equivalent with the set of f's zeros. Moreover, the fixed points are also called critical points.

The fixed points of a dynamic system defined through an autonomous system can be interpreted as constant solutions of the autonomous system \eqref{1.12}. For this reason, the fixed points can be also called equilibrium points.
\subsection{Limit sets and attractors}

Let $(X,\R,\varphi)$ be a dynamic system. Let $\Gamma_{x}=\varphi(\R,x)$ be a trajectory of this dynamic system. A point (a state) $x_{0}\in X$ is called $\omega-$limit point of the trajectory $\Gamma_{x}$, if exists $t_{n}\in\R, t_{n}\rightarrow \infty$ such that $$\lim_{t_{n}\rightarrow\infty}\varphi(t_{n},x)=x_{0}.$$ We note with $\omega(x)$ teh set of $\omega-$limit points of $\Gamma_{x}$. 
\begin{theorem}
 Let $\Gamma_{x}$ be a trajectory of the dynamic system $(X,\R,\varphi)$. If $x_{1}\in\Gamma_{x}$, then $\omega(x_{1})=\omega(x)$.
\end{theorem}
\begin{proof}
 From $x_{1}\in\Gamma_{x}=\varphi(\R,x)$ results that exists $s\in\R: x_{1}=(s,x)$. Let $p\in\omega(x)$. Thus exists $t_{n}$ such that $$\lim_{t_{n}\rightarrow\infty}\varphi(t_{n},x)=p.$$ How $\varphi(t_{n},x)=\varphi(t_{n}-s,x_{1})$, results that $p\in\omega(x_{1})\Leftrightarrow p\in\omega(x)$.
\end{proof}
The ennounced theorem shows that the set $\omega(x)$ depends only of the trajectory that passes through $x$. Thereby, we may also use the notation $\omega(\Gamma_{x})$ in place of $\omega(x)$.
Further more, if $A\subset X$, then $$\omega(A):=\cup_{x\in A} \omega(x).$$
\begin{theorem}
 Let $A\subset X$ be a closed set, such that $\varphi(t,A\subset A, \forall t\in \R_{+}$. If $a\in A$, then $\omega(a)\subset A$.
\end{theorem}
\begin{proof}
 Let $p\in\omega(a)$. Thus exists $t_{n}\in\R_{+}, t_{n}\rightarrow \infty$ such that $\varphi(t_{n},a)\rightarrow p$. Although $\varphi(t_{n},a)\in A$ and $A$ is closed, results that $p\in A$.
 
\end{proof}
\remark Set $\varphi(\R_{+},a)$ is called the positive semitrajectory (semiorbit) of a. A subset $A\subset X$ with the property that $\varphi(\R_{+},a),\forall a\in A$ is called positive invariant.
\begin{theorem}
 Let $(X,\R,\varphi)$ be a dynamic system. The $\omega-$limit set of a trajectory is closed and invariant.
\end{theorem}

Consider $(X,\R,\varphi)$ a dynamic system. A subset $A\subset X$, invariant and closed, is called attractive if exists a neighborhood $V$ of $A$, positive invariant with property that for all $x\in A$ $$\varphi(t,x) \rightarrow A,$$ when $t\rightarrow \infty.$ A subset $A\subset X$ is called attractor for the dynamic system if it is attractive and contains a thick trajectory. 
\subsection{Dynamic systems in $\R^{n}$}
 Considering a dynamic system in $R^{n}$ defined by an autonomous system \eqref{1.12}, the following result occur.
 \begin{theorem}
  Let $(\R^{n},\R,\varphi)$ be a dynamic system on $\R^{n}$. We presume that $\varphi\in C^{1}(\R\times\R^{n},\R^{n})$. We note $$f(\eta):=\frac{\partial \varphi(0,\eta)}{\partial t}.$$ Then $\varphi(\cdot,\eta)$ is the solution of the Cauchy problem 
  \begin{equation}\label{1.14}
   x'=f(x),x(0)=\eta.
  \end{equation}

 \end{theorem}
\begin{proof}
 We have:
 \begin{align*}
  x'(t)&=\frac{\partial \varphi(t,\eta)}{\partial t}=\lim_{h\rightarrow 0}\frac{\varphi(t+h,\eta)-\varphi(t,\eta)}{h}= \\
       &=\lim_{h\rightarrow 0}\frac{\varphi(h,\varphi(t,\eta))-\varphi(0,\varphi(t,\eta))}{h}=f(\varphi(t,\eta)), \forall t\in \R.  
 \end{align*}
and $$x(0)=\varphi(0,\eta)=\eta.$$
\end{proof}
Hence all the dynamic systems from $\R^{n}$, of class $C^{1}$, can be presented through systems of autonomous differential equations.
\subsection{The phase portrait of a dynamic system}
 We will call the phase portrait of a dynamic system the set of trajectories of the relative system. The notions introduced in the previous sections are fundamental for sketching the phase portrait of a dynamic system. In this regard, the following examples are relevant.
 \paragraph{Example 1} Let us consider the Cauchy problem:
 \begin{equation*}
  \begin{cases}
   x'=0\\
   x(0)=\eta
  \end{cases}
 \end{equation*}
By solving the equation with separable variables, we obtain that the solution is $\xstar(t)=c, c\in\R$. Meaning that the flux of the equation is $\varphi(t,\eta)=\eta$. Then the generated dynamic system is $(\R,\R,\varphi)$.  All the solutions of the equation are equilibrium solutions.\begin{figure}[h]
\caption{The direction field for Example 1.}
\centering
 \includegraphics[width=10cm]{Portretfazicex1.eps}
\end{figure}
\paragraph{Example 2} Let us consider the Cauchy problem:
\begin{equation*}
 \begin{cases}
  x'=2x\\
  x(0)=\eta
 \end{cases}
\end{equation*}
By solving the equation with separable variables, we obtain the solution $\xstar(t)=c\cdot e^{2t}$. The flux of the equation is $\varphi(t,\eta)=\eta e^{2t}$. The equation has a single equilibrium point $x=0$. The generated dynamic system is $(\R,\R,\varphi)$.
\begin{figure}[h]
\caption{The direction field for Example 2.}
\centering
 \includegraphics[width=10cm]{Portretfazicex2.eps}
\end{figure}
 \paragraph{Example 3} Let us consider the Cauchy problem:
 \begin{equation*}
  \begin{cases}
   x'=-2x\\
   x(0)=\eta
  \end{cases}
 \end{equation*}
By solving the differential equation, we obtain the solution $\xstar(t)=c\cdot e^{-2t}$. The flux of the equation is $\varphi(t,\eta)=\eta e^{-2t}$. The equation has a single equilibrium point $x=0$. The generated dynamic system is $(\R,\R,\varphi)$.
\begin{figure}[h]
\caption{The direction field for Example 3.}
\centering
 \includegraphics[width=10cm]{Portretfazicex3.eps}
\end{figure}
 \paragraph{Example 4} Let us consider the following system:
 \begin{equation*}
  \begin{cases}
   x'=x\\
   y'=y
  \end{cases}
 \end{equation*}
By solving the differential equations, we obtain the solutions $\xstar(t)=c_{1}\cdot e^{t}$ and $y^{*}(t)=c_{2}\cdot e^{t}$. The flux of the equation is $\varphi(t,\eta)=\begin{bmatrix}                                                                                                                                                                         
\eta_{1} \\ \eta_{2}                                                                                                                                                                           \end{bmatrix}
 \begin{bmatrix}
  e^{t} && 0 \\ 0 && e^{t}
 \end{bmatrix}$. The equation has a single equilibrium point $x=0$. The generated dynamic system is $(\R^{2},\R,\varphi)$.
 \remark The trajectories of the system can be found by solving: $$\frac{dy}{dx}=\frac{Q(x,y)}{P(x,y)},$$ where $Q(x,y)=\frac{dy}{dt}$ and $P(x,y)=\frac{dx}{dt}$.
 In this example, the trajectories of the system are given by the equation $y-x=c,c\in\R$.
\begin{figure}[h]
\caption{The direction field for Example 4.}
\centering
 \includegraphics[width=10cm]{Portretfazicex4.eps}
\end{figure}
\paragraph{Example 5} Let us consider the following system:
 \begin{equation*}
  \begin{cases}
   x'=-y\\
   y'=x
  \end{cases}
 \end{equation*}
By solving the differential equations, we obtain the solutions $\xstar(t)=c_{1}\cdot e^{t}$ and $y^{*}(t)=c_{2}\cdot e^{t}$. The flux of the equation is $\varphi(t,\eta)=\begin{bmatrix}                                                                                                                                                                         
\eta_{1} \\ \eta_{2}                                                                                                                                                                           \end{bmatrix}
 \begin{bmatrix}
  e^{t} && 0 \\ 0 && e^{t}
 \end{bmatrix}$. The equation has a single equilibrium point $x=0$. The generated dynamic system is $(\R^{2},\R,\varphi)$.
 \remark The trajectories of the system can be found by solving: $$\frac{dy}{dx}=\frac{Q(x,y)}{P(x,y)},$$ where $Q(x,y)=\frac{dy}{dt}$ and $P(x,y)=\frac{dx}{dt}$.
 In this example, the trajectories of the system are given by the equation $y-x=c,c\in\R$.
\begin{figure}[h]
\caption{The direction field for Example 5.}
\centering
 \includegraphics[width=10cm]{Portretfazicex5.eps}
\end{figure}

\section{IS-LM dynamics}
\subsection{The static model}
The models includes a set of equations that denote behavioural relationships for expenditures, along with an equilibrium condition. All together comprise the goods market. Investment is considered to be inversely proportional to the rate of interest. Consumers' expenditure related to disposable income is defined as income less direct taxes. We consider a closed economy, thus total expenditure is the sum of consumers' expenditure, investment expenditure and government expenditure. We consider government expenditure as the only exogenous variable in the present model. The equilibrium condition regarding the goods market is that income is equal to total expenditure. The goods market equations are set out algebraically in the upper section of table:

\begin{table}[]
\begin{tabular}{|l|l|l|}
\hline
Goods market    & Conditions        & Definitions              \\ \hline
$C=a+bYd$       & $0\leq b\leq 1$   & C=consumers' expenditure \\ \hline
$Yd=Y-Tx$       &                   & Yd=disposable income     \\ \hline
$Tx=Tx_{0}+txY$ & $0\leq tx \leq 1$ & Tx=total taxes           \\ \hline
$I=I_{0}-hr$    & $h>0$             & r=interest rate          \\ \hline
$Y=C+I+G$       &                   & I=investment expenditure \\ \hline
                &                   & G=government expenditure \\ \hline
\end{tabular}
\end{table}
which indicate the Goods market equations. The terms $a$, $Tx_{0}$ and $I_{0}$ denote autonomous expenditures. Parameter $b$ denotes the marginal propensity to consume and $tx$ represents the marginal rate of tax. Equation $Y=C+I+G$ represents the equilibrium condition in the goods market.\par
By substitutions, we get the following condition for goods market equilibrium:
\begin{equation}\label{incomeislm}
 Y=(a-bTx_{0}+I_{0}+G)+b(1-tx)Y-hr
\end{equation}
\begin{equation}\label{margrate}
 r=\frac{(a-bTx_{0}+I_{0}+G)}{h}-\frac{1-b(1-tx)Y}{h}
\end{equation}
Equation \eqref{margrate} can be written more simply as:
\begin{equation}\label{simple mr}
 r=A_{0}-A_{1}Y \\
 A_{0}=\frac{(a-bTx_{0}+I_{0}+G)}{h} \\
 A_{1}=\frac{1-b(1-tx)Y}{h}
\end{equation}
In general, we will have a positive intercept and a negative slope when drawing in $(Y,r)$-space, with $Y$ on the horizontal axis and $r$ on the vertical axes.
Next, let us consider the money market. The money supply is assumed exogenous and set at $M$. Substituting this into the equilibrium condition, we get:
\begin{equation*}
 M_{0}=kY-ur=M
\end{equation*}
or
\begin{equation}\label{money mr}
 r=\frac{M_{0}-M}{u}+\frac{kY}{u}
\end{equation}
Simpler:
\begin{equation}\label{simpler money mr}
 r=B_{0}+B_{1}Y\\
 B_{0}=\frac{M_{0}-M}{u} \\
 B_{1}=\frac{kY}{u}
\end{equation}
In this case, the slope will be positive when drawn in $(Y,r)$-space, due to our assumptions about the sign of the parameters $k$ and $u$. The intercept can be positive, zero or negative.
Now we have two equations: \eqref{simpler money mr} and \eqref{simple mr}, with $Y$ and $r$ unknown. The situation is represented graphically in figure
\begin{figure}[h]
\caption{IS-LM model\cite{shone}}
\centering
 \includegraphics[width=10cm]{IS-LM.png}
\end{figure}
The goods market equilibrium is labelled IS and the money market equilibrium is labelled LM. All-round equilibrium is the point where the two lines intersect, leading to equilibrium levels $Y^{*}$ and $r^{*}$. 
A rise in the government spending raises the intercept $A_{0}$ and so shifts the curve IS to the right. Similarly, a rise in the money supply reduces the intercept $B_{0}$ and so shifts the LM curve down. In each case there is a rise in the level of national income. For fiscal expansion, there is a rise in the rate of interest and in the case of a monetary expansion there is a fall in the rate of interest.
\subsection{A continuous model}
Let us consider a continuous model and also allow differential adjustments in both the money market and the goods market, neither of which is instantaneous. We assume that the money market is quicker to adjust than the goods market. In the goods market, we assume that income rises over time if there is excess demand and falls if there is excess supply. More specifically:
\begin{equation}
 Y'(t)=\alpha(E(t)-Y(t)), \alpha>0
\end{equation}
where $E(t)=C(t)+I(t)+G$. In the money market we assume that the interest rate rises if there is excess demand in this market and falls if there is excess supply. Meaning:
\begin{equation}
 r'(t)=\beta(Md-Ms),\beta>0
\end{equation}
Thus, the model is:
\begin{align}
 C(t)&=a+bYd(t) \\
 Yd(t)&=Y(t)-Tx(t) \\
 Tx(t)&=Tx_{0}+txY(t)\\
 I(t)&=I_{0}-hr(t)\\
 E(t)&=C(t)+I(t)+G\\
 Y'(t)&=\alpha(E(t)-Y(t)), \alpha>0\\
 Md(t)&=M_{0}+kY(t)-ur(t)\\
 Ms(t)&=M\\
 r'(t)&=\beta(Md-Ms),\beta>0.
\end{align}
In equilibrium, $Y'(t)=0$ meaning that $Y(t)=C(t)+I(t)+G$ and $r'(t)=0$ meaning that $Md(t)=Ms(t)=M$. Moreover, both equilibrium conditions do not depend on the adjustment coefficients $\alpha$ and $\beta$.By substituting all the relationships in each of the adjustment equations in turn, results:
\begin{align*}
 \text{IS: }&Y'(t)=\alpha(a-bTx_{0}+I_{0}+G)-\alpha(1-b(1-tx))Y(t)-\alpha hr(t) \\
 \text{LM: } &r'(t)=\beta(M_{0}-M)+\beta k Y(t)-\beta ur(t).
\end{align*}
It can be rapidly noticed that the IS curve is the isocline $Y'=0$ and the LM curve is the isocline $r'=0$. We consider that $(1-b(1-tx))>0$ and $k,u>0$.
Considering first the goods market, if $Y'(t)>0$ then $Y(t)$ is rising. This will occur when:
$$\alpha(a-bTx_{0}+I_{0}+G)-\alpha(1-b(1-tx))Y(t)-\alpha hr(t)>0$$
$$r(t)<\frac{(a-bTx_{0}+I_{0}+G)}{h}-\frac{(1-b(1-tx))Y(t)}{h}$$
This refers to points below the IS curve. Thus, there is pressure for income to rise. Above the IS curve, there is pressure for income to fall.
In the money market, if $r(t)>0$ then $r(t)$ is rising and
$$\beta(M_{0}-M)+\beta kY(t)-\beta ur(t)>0$$
$$r(t)<\frac{M_{0}-M}{u}+\frac{kY(t)}{u}$$
hence below the LM curve is pressure on interest rates to rise, while above there is pressure on interest rates to fall. 

\section{Conclusions}
The chapter introduced the reader to the general notions of an equation with separable variables, of linear differential equations of first order and the linear differential systems, needed for presenting the main part of the paper. The notions have been extracted from the classic books mentioned in the bibliography of the paper. The author's contribution was the selection and solving of the examples found at the end of each section.

    
    
    \chapter{Difference Equations}
    \section{Introduction}
    In this chapter, we will introduce the general form of a linear difference equation and its particular cases, followed by the generated dynamical systems. Later, we will present the notion of equilibrium point, the stability criteria and a few important results. The author's contribution are the selection and solving of the examples from the end of each section.
    \section{Linear difference equations of first order}
    The general form of a linear difference equation of first order is:
    \begin{equation} 
     x_{n+1}=a_{n}x_{n}+b_{n} \label{2.1}
    \end{equation}
    for any $n \geq 0$, where $(a_{n})_{n\geq 0}$ and $(b_{n})_{n\geq 0}$ are given series of real numbers. 
\eqref{2.1} is obtained starting from an initial value $x_{0} \in \R$. Hence:
\begin{align*}
 x_{1} & =a_{0}x_{0}+b_{0}\\
   x_{2} & =a_{1}x_{1}+b_{1} = a_{1}(a_{0}x_{0}+b_{0})+b_{1}\\
  & = a_{1}a_{0}x_{0}+a_{1}+b_{0}+b_{1}\\
  & ...\\
   x_{n}&=a_{n-1}x_{n-1}+b_{n-1} = a_{n-1}\cdot ... \cdot a_{0}x_{0}+a_{n-1}\cdot ...\cdot a_{1}b_{0}+...+a_{n-1}\cdot b_{n-2}+b_{n-1}.
\end{align*}

Through mathematical induction, it is proved that the solution of the linear difference equation of first order has the following form:
\begin{equation}\label{2.2}
 x_{n}=\bigg( \prod_{j=0}^{n-1} a_{j} \bigg) \cdot x_{0} + \sum_{j=0}^{n-1} \bigg( \prod_{k=j+1}^{n-1} a_{k} \bigg)\cdot b_{j}.
\end{equation}
If \eqref{2.1} is valid for $n$ starting from an $n_{0} \geq 0$, meaning that:
\begin{equation}\label{2.3}
 x_{n+1}=a_{n}\cdot x_{n}+b_{n}, n\geq n_{0}
\end{equation}
Then \eqref{2.2} becomes:
\begin{equation}
 x_{n}=\bigg( \prod_{j=n_{0}}^{n-1} a_{j} \bigg) \cdot x_{n_{0}} + \sum_{j=n_{0}}^{n-1} \bigg( \prod_{k=j+1}^{n-1} a_{k} \bigg)\cdot b_{j}.
\end{equation}
Ordinarilly, there are multiple particular cases of \eqref{2.1} that can appear in practice, which ease the use of formula \eqref{2.2}.
\subsection{Particular cases of linear difference equations of first order}
\subsubsection{Case $a_{n}\equiv a$} \label{i}
In this case, \eqref{2.1} becomes:
\begin{equation}
\label{2.6}
 x_{n+1}=a\cdot x_{n}+b_{n}, n\geq 0,
\end{equation}
where $a\in \R$ and $(b_{n})_{n\in\mathbb{N}}$ is a given series of real numbers.
From \eqref{2.1} we have that:
\begin{align*}
 \prod_{j=0}^{n-1} a_{j} &=\prod_{j=0}^{n-1} a,\\
 \prod_{k=j+1}^{n-1} a_{k}&=\prod_{k=j+1}^{n-1} a=a^{n-1-(j+1)+1}=a^{n-j-1}
\end{align*}
and the solution is:
\begin{equation}\eqref{2.6}
 x_{n}=a^{n}\cdot x_{0}+\sum_{j=0}^{n-1} a^{n-j-1}\cdot b_{j}.
\end{equation}

\subsubsection{Case $b_{n}\equiv b$}\label{2.1.1.2}
In this case, \eqref{2.1} becomes:
\begin{equation}\label{2.7}
 x_{n+1}=a_{n}\cdot x_{n}+b, n\geq 0,
\end{equation}
where $b\in\R$ and $(a_{n})_{n\in\mathbb{N}}$ is a given series of real numbers.
From \eqref{2.2}, we obtain:
\begin{align*}
 x_{n} &= \bigg( \prod_{j=0}^{n-1} a_{j} \bigg) \cdot x_{0} + \sum_{j=0}^{n-1}\bigg(\prod_{k=j+1}^{n-1} a_{k}\bigg)\cdot b_{j} =\\
 &= \bigg( \prod_{j=0}^{n-1} a_{j} \bigg) \cdot x_{0} + \sum_{j=0}^{n-1}\bigg(\prod_{k=j+1}^{n-1} a_{k}\bigg)\cdot b
\end{align*}
meaning that the solution is of form:
\begin{equation}
 x_{n}=\bigg( \prod_{j=0}^{n-1} a_{j} \bigg)\cdot x_{0}+b\cdot\sum_{j=0}^{n-1}\bigg(\prod_{k=j+1}^{n-1} a_{k}\bigg).
\end{equation}
\subsubsection{Case $a_{n}\equiv a$ and $b_{n}\equiv b$}
In this case, \eqref{2.1} becomes:
\begin{equation}
 x_{n+1}=a\cdot x_{n}+b, n\geq 0,
\end{equation}
where $a,b\in \R$.
From \eqref{2.2} we obtain:
\begin{align*}
 x_{n} &= \bigg(\prod_{j=0}^{n-1} a \bigg)\cdot x_{0}+\sum_{j=0}^{n-1}\bigg(\prod_{k=j+1}^{n-1}a\bigg)\cdot b=\\
 &=a^{n}\cdot x_{0}+b\cdot \sum_{j=0}^{n-1} a^{n-j-1}=\\
 &=a^{n}\cdot x_{0}+b\cdot (a^{n-1}+a^{n-2}+...+a^{0}).
\end{align*}
If $a \neq 1$, we have:
\begin{align*}
 x_{n}&=a^{n}\cdot x_{0}+b\cdot \frac{a^{n}-1}{a-1}=\\
 &= a^{n}\cdot \bigg(x_{0}+\frac{b}{a-1}\bigg)-\frac{b}{a-1}.
\end{align*}
And if $a=1$, we have:
\begin{align*}
 x_{n}&=a^{n}\cdot x_{0}+b(a^{n-1}+a^{n-2}+...+a^{0})=\\
 &=x_{0}+n\cdot b.
\end{align*}
Thus the solution is:

 $$x_{n}=\begin{cases}
        a^{n}\cdot \big(x_{0}+\frac{b}{a-1}\big)-\frac{b}{a-1}, a\neq 1 \\
        x_{0}+n\cdot b, a=1.
       \end{cases}
$$

\subsection{Examples}
\paragraph{1)} $x_{n+1}=-x_{n}+n$\\ \\
\underline{Solution:}
In this example, $a_{n}=a=-1\in\R$, meaning we are in case \ref{i}. Then, the products become:
$$ \prod_{j=0}^{n-1} a=a^{n}=(-1)^{n}$$
and 
$$\prod_{k=j+1}^{n-1} a=(-1)^{n-j-1}.$$ 
Hence, by applying \eqref{2.6}, the solution is:
$$x_{n}=(-1)^{n}\cdot x_{0}+\sum_{j=0}^{n-1} (-1)^{n-j-1}\cdot j.$$
Let us choose $x_{0}=1$, then the solution is: 
$$ x_{n}=(-1)^{n}+\sum_{j=0}^{n-1} (-1)^{n-j-1}\cdot j.$$

\paragraph{2)} $x_{n+1}=\frac{n+2}{n+1}\cdot x_{n}$.\\ \\
\underline{Solution:}\\ \\
In this example, $a_{n}=\frac{n+2}{n+1}$ and $b_{n}=0 \in \R$, meaning we are in case \ref{2.1.1.2}. Then, the solution is:
$$ x_{n}=\prod_{j=0}^{n-1} \frac{j+2}{j+1}\cdot x_{0}=\frac{2}{1}\cdot ...\cdot \frac{n+2}{n+1} \cdot x_{0} =(n+2)\cdot x_{0}.$$
Let us choose $x_{0}=1$. Then the solution is: $x_{n}=n+2$.

\paragraph{3)} $x_{n+1}=2x_{n}+3^{n}$, $x_{0}=1$.\\ \\
\underline{Solution:}
We will find the general term by solving the equation step by step. Hence we have:
\begin{align*}
 x_{1}&=2x_{0}+3^{0}\\
 x_{2}&=2x_{1}+3^{1}=2(2x_{0}+3^{0})+3^{1}=2^{2}x_{0}+2\cdot 3^{0}+3^{1}\\
 x_{3}&=2x_{2}+3^{2}=2(2^{2}x_{0}+2\cdot 3^{0}+3^{1})+3^{2}=2^{3}x_{0}+2^{2}\cdot 3^{0}+2\cdot 3^{1}+3^{2}\\
 &.\\ &.\\ &.\\
 x_{n}&=2^{n}x_{0}+2^{n-1}3^{0}+2^{n-2}3^{1}+...+2\cdot 3^{n-2}+3^{n-1}.
\end{align*}
We can now presume that
$$x_{n}=2^{n}x_{0}+\sum_{k=0}^{n-1} 2^{n-1-k}3^{k}+3^{n-1}.$$

The sum can be written: $$ 2^{n-1}\sum_{k=0}^{n-1}\bigg(\frac{3}{2}\bigg)^{k}.$$ Solving the resulted sum of a geometric progression, we get:
$$2^{n-1}\sum_{k=0}^{n-1}\bigg(\frac{3}{2}\bigg)^{k}=2^{n}\cdot \bigg[ (\frac{3}{2})^{n-1}-1\bigg].$$
Thus, the general term of the difference equation is:
$$x_{n}=2^{n}\cdot 1+2^{n}\bigg[ \bigg(\frac{3}{2}\bigg)^{n-1}-1\bigg]+3^{n-1}.$$




\section{Dynamical systems}

\subsection{Dynamical systems defined by a linear difference equation of first order}
\subsubsection{Example}\label{2.2.2.1} Let us consider the difference equation:
\begin{equation}
 x_{n+1}=ax_{n}, a\in \R^{*} \label{2.10}
\end{equation}
We know that $x_{n}=a^{n}x_{0}, x_{0}\in\R$ represents the solution of \eqref{2.10} with start value $x_{0}\in\R$. Let us define $\varphi:\mathbb{Z}x\R\rightarrow X$ through:
$$\varphi(k,x)=a^{k}x.$$
then $(\R,\mathbb{Z},\varphi)$ is an inversable discrete dynamical system generated by \eqref{2.10}.
\subsubsection{Example}\label{2.2.2.2}
Let $f:\R\rightarrow\R$ and the difference equation:
\begin{equation}\label{2.11}
 x_{n+1}=f(x_{n}).
\end{equation}
We note through
\begin{equation}\label{2.12}
 x_{n}(x_{0})=\underbrace{(f\circ...\circ f)}_\text{of n times}(x)=f^{n}(x_{0}), x_{0}\in\R
\end{equation}
the solution of the equation with start value $x_{0}\in\R$. We define $\varphi:\mathbb{N}x\R\rightarrow\R$ through:
\begin{equation*}
 \varphi(n,x)=f^{n}(x),
\end{equation*}
then $(\R,\mathbb{N},\varphi)$ is a discrete dynamical system generated by \eqref{2.11}. The trajectory of the dynamical system that passes through $x_{0}\in\R$ is given by the set:
\begin{equation}\label{2.13}
 \varphi(\mathbb{N},x_{0})=O_{f}(x_{0})=\{x_{0},x_{1},...,x_{n},...\}
\end{equation}
named also the orbit generated by $x$ through $f$.
\begin{definition}
 Let $(X,G,\varphi)$ be a dynamical system. We say that $\xstar\in X$ is a fixed point of the dynamical system if $\varphi(t,\xstar)=\xstar,\forall t\in G$.
\end{definition}
Let us consider the dynamical system generated by \eqref{2.11}. If $\xstar \in \R$ is a fixed point for this dynamical system, then:
\begin{align*}
 \varphi(n,\xstar)&=\xstar, \forall n\in\mathbb{N}\\
 f^{n}(\xstar)&=\xstar,\forall n\in\mathbb{N}
\end{align*}
from where we deduce that $\xstar\in\R$ is a solution for the equation $f(x)=x$. So the orbit generated by the fixed point $\xstar$ is reduced to a point
\begin{equation*}
 \varphi(\mathbb{N},\xstar)=O_{f}(\xstar)=\{\xstar\}.
\end{equation*}
\section{Dynamics generated by difference equations of first order}
\subsection{Equilibrium point. Stability criteria}
As we have seen in \ref{2.2.2.2}, the difference equation of first order:
\begin{equation}\label{2.14}
 x_{n+1}=f(x_{n})
\end{equation}
generates the dynamical system $(\R,\mathbb{N,\varphi})$, where $\varphi(n,x)=f^{n}(x)$. The fixed points of this dynamical system are given by the solutions of the equation
\begin{equation}\label{2.15}
 x=f(x)
\end{equation}
From the perspective of the difference equation \eqref{2.14}, the fixed points of the generated dynamical system are obtained from the constant solutions:
\begin{equation}\label{2.16}
(x_{n})=(\xstar,\xstar,...\xstar)
\end{equation}
where $\xstar\in\R$ is the solution of \eqref{2.15}.
\begin{definition}
 A point $\xstar\in\R$ is called an equilibrium point (stationary) for equation \eqref{2.14} if it is a fixed point for the generated dynamical system $(\R,\mathbb{N},\varphi)$. The constant solution defined by \eqref{2.16} is called equilibrium solution (stationary).
\end{definition}
One of the main objectives in the study of dynamics generated by difference equations is the study of the behaviour of their solutions to the equilibrium solutions. We will introduce the stability notions that describe this behaviour:
\begin{definition}
 We say that an equilibrium point $\xstar\in\R$ for \eqref{2.14} is:
 \begin{enumerate}
  \item \textbf{global atractor} relative to set $D\subseteq\R$ if:
  $$x_{n}(x_{0})=\varphi(x,x_{0})\rightarrow\xstar,n\rightarrow\infty,\forall x_{0}\in D$$
  \item \textbf{locally stable} if for any $\epsilon>0$ exists $\delta>0$ such that if $|x_{0}-\xstar|<\delta$ then:
  $$|x_{n}(x_{0})-\xstar|<\epsilon,\forall n\in\mathbb{N}$$
  \item \textbf{locally asymptotic stable} if it is locally stable and exists $\eta>0$ such that if $|x_{0}-\xstar|<\eta$ then: $$|x_{n}(x_{0})-\xstar|\rightarrow\xstar, n\rightarrow \infty$$
  \item \textbf{globally asymptotic stable} relative to set $D\subseteq\R$ if it is locally asymptotic stable and is global atractor relative to set $D$;
  \item \textbf{exponentially stable} relative to set $D\subseteq\R$ if exists $\alpha\in [0,1)$ and $c(x_{0})>0$ such that:
  $$|x_{n}(x_{0})-\xstar|\leq c(x_{0})\cdot\alpha^{n},\forall x_{0}\in D$$
  \item \textbf{unstable} if it is not locally stable, meaning that exists $\epsilon>0$ such that for any series $(x_{l}^{o})_{l\in\mathbb{N}}$ which satisfy $x_{l}^{o}\rightarrow\xstar$ exists $N_{l}\in\mathbb{N}$ such that:
  $$|x_{N_{l}}(x_{l}^{o})-\xstar|>\epsilon$$
 \end{enumerate}
\end{definition}
\begin{remark}
 Any exponentially stable equilibrium point relative to set $D\subseteq\R$ is globally asymptotic stable relative to set $D\subseteq\R$.
\end{remark}
\subsubsection{Cobweb Diagram}
The Cobweb diagram represents the graphic visualization of a dynamic generated by a difference equation of form \eqref{2.14}. It is built in the following way:
\begin{enumerate}
 \item We calculate $x_{1}=f(x_{0})$, for a given $x_{0}$;
 \item We draw the vertical from $x_{0}$ until it intersects the graphic of $f$ in $(x_{0},f(x_{0}))=(x_{0},x_{1})$;
 \item We draw the horizontal line from $(x_{0},x_{1})$ until it intersects the diagonal $y=x$, thus obtaining the point $(x_{1},x_{2})$.
\end{enumerate}
The intersection of the vertical from $(x_{1},x_{1})$ with the graphic of $f$ represents the point $(x_{1},f(x_{1}))={x_{1},x_{2}}$. The process continues until we determine $x_{n}$ relative to a fixed $N$. Thus, the Cobweb diagram is obtained and it provides us information regarding the stability of the equilibrium points.
\subsection{Stability criteria of the equilibrium points}
\begin{theorem}
 Let us consider \eqref{2.14} for which $f:I\rightarrow I$,$I\subseteq\R$ is a closed interval. If f is an $\alpha$-contraction, meaning that there exists $\alpha\in [0,1)$ such that
 $$|f(x)-f(y)|\leq \alpha |x-y|, \forall x,y\in I$$
 then:
 \begin{enumerate}
  \item \eqref{2.14} has an unique equilibrium point $\xstar\in I$;
  \item the equilibrium point $\xstar$ is exponentially stable:
  \begin{equation}\label{2.17}
|x_{n}(x_{0})-\xstar|\leq\frac{\alpha^{n}}{1-\alpha}\cdot |f(x_{0})-x_{0}|, \forall x_{0}\in I
\end{equation}
 \end{enumerate}
\end{theorem}
\begin{proof}
 Let $x_{0} \in I$ and let us consider $x_{n}(x_{0})=f^{n}(x_{0})$ the solution of quation $x_{n+1}=f(x_{n})$. From the contraction condition we denote that $$|x_{n+1}(x_{0}-x_{n}(x_{0})|\leq \alpha |x_{n}(x_{0})-x_{n-1}(x_{0})|\leq ... \leq \alpha^{n}|fx_{0}-x_{0}|,$$
 from where we obtain that
 \begin{align*}
  |x_{n+p}(x_{0})-x_{n}(x_{0})| &\leq \sum_{j=0}^{p-1} |x_{n+j+1}(x_{0})-x_{n+j}(x_{0})|\leq \\
  &\leq \bigg(\sum_{j=0}^{p-1} \alpha^{n+j}\bigg) |f(x_{0})-x_{0}|= \\
  &=\alpha^{n}\cdot\frac{1-\alpha^{p}}{1-\alpha}|f(x_{0})-x_{0}|\leq \frac{\alpha^{n}}{1-\alpha}|f(x_{0})-x_{0}|.
 \end{align*}
We can observe that for $n\rightarrow \infty$ and for all $p\in \mathbb{N}$ we have $|x_{n+p}(x_{0})-x_{n}(x_{0})|\rightarrow 0$, meaning that the series $(x_{n}(x_{0}))_{n\in\mathbb{N}}$ is fundamental. With $I\subseteq \R$ being a closed interval, we have that the series $(x_{n}(x_{0}))_{n\in\mathbb{N}}$ is convergent. Let $x^{*}=\lim_{n\rightarrow\infty} x_{n}(x_{0})$. $I$ is a closed interval, so $x_{*}\in I$.
From $$x_{n+1}(x_{0})=f(x_{n}(x_{0}))$$ and f being continuous, applying the limit in the relation above we obtain:
$$x^{*}=f(x^{*})$$ meaning that $x^{*}$ is an equilibrium point for \eqref{2.14}. If $x^{*}$ and $y^{*}$ are two equilibrium points for \eqref{2.14}, then:
$$|x^{*}-y^{*}|\leq|f(x^{*})-f(y^{*})| \leq \alpha|x^{*}-y^{*}|,$$
hence
$$(1-\alpha)|x^{*}-y^{*}|\leq 0,$$
which implies that $|x^{*}-y^{*}|=0$, so $x^{*}=y^{*}$, meaning that \eqref{2.14} admits an unique equilibrium point. Estimation \eqref{2.17} is given by the inequality:
$$|x_{n+p}(x_{0})-x_{n}(x_{0})|\leq \alpha^{n} \frac{1-\alpha^{p}}{1-\alpha}|f(x_{0})-x_{0}|$$
By making $p\rightarrow\infty$, the exponential stability of the equilibrium point $x^{*}$ is proven.

\end{proof}
\begin{theorem}\label{2.3.2.2.}
 Considering \eqref{2.14} for which $f:I\rightarrow I, I\subseteq\R$ is an interval, we presume that:
 \begin{enumerate}
  \item \eqref{2.14} has an unique equilibrium point $\xstar\in I$;
  \item $f$ is an $\alpha$-cvasicontraction, meaning that there exists $\alpha\in[0,1)$ such that:
  $$|f(x)-\xstar|\leq \alpha |x-\xstar|, \forall x\in I.$$
   \end{enumerate}
  Then the equilibrium point $\xstar$
  \begin{equation}\label{2.18}
   |x_{n}(x_{0})-\xstar|\leq\alpha^{n}|x_{0}-\xstar|,\forall x_{0}\in I.
  \end{equation}
\end{theorem}

\begin{proof}
 Let $x_{0}\in I$ and let us consider $x_{n}(x_{0})=f^{n}(x_{0})$ the solution of \eqref{2.14}, with $x_{0}$ as the starting value. Estimation \eqref{2.18}, which demonstrates the exponential stability of the equilibrium point $x^{*}$, can be proved through mathematical induction by using the $\alpha$-cvasicontraction condition. Hence:
 \begin{align*}
  |x_{1}(x_{0})-x^{*}|&\leq\alpha |x_{0}-x^{*}|,\\
  |x_{2}(x_{0})-x^{*}|&\leq |x_{1}(x_{0})-x^{*}| \leq\alpha |x_{0}-x^{*}|,\\
  &.\\
  &.\\
  &.\\
  |x_{n}(x_{0})-x^{*}|&\leq \alpha^{n}|x_{0}-x^{*}|.
 \end{align*}
\end{proof}

\begin{theorem}[The stability criteria in first aproximation]\label{2.3.2.3.}
 Let $\xstar\in I$ be an equilibrium point for \eqref{2.14}, $f:I\rightarrow\R$ such that f is differentiable in $\xstar$. Then:
 \begin{enumerate}
  \item if $\xstar$ is locally stable, then $|f'(\xstar)|\leq 1$;
  \item if $|f'(\xstar)|<1$ then $\xstar$ is locally asymptotic stable;
  \item if $|f'(\xstar)|>1$ then $\xstar$ is unstable.
 \end{enumerate}
\end{theorem}
\begin{proof}
 (a) How f is differentiable in $x^{*}$ then:
 \begin{equation*}
  |f'(x^{*})|=\lim_{x\rightarrow x^{*}} \frac{|f(x)-f(x^{*})|}{|x-x^{*}|}
 \end{equation*}
If the equilibrium point $x^{*}$ is locally stable, then for all $\epsilon>0$ exists $\delta>0$ such that if $|x_{0}-x^{*}|<\delta$ we have:
\begin{align*}
 |x_{n}(x_{0})-x^{*}|&<\epsilon, \forall n\in\mathbb{N} \\
 |f^{n}(x_{0})-x^{*}|&<\epsilon, \forall n\in\mathbb{N}
\end{align*}
For a fixed $x\in I$ we choose $\epsilon=|x-x^{*}|$ and from $x^{*}$'s property of local stability we obtain:
\begin{equation*}
 |f^{n}(x)-x^{*}|<\epsilon=|x-x^{*}|, \forall n\in\mathbb{N},
\end{equation*}
so for $n=1$ we have:
\begin{align*}
 |f(x)-x^{*}|&<|x-x^{*}|,\\
 \frac{|f(x)-x^{*}|}{|x-x^{*}|}&<1,
\end{align*}
and by applying the limit $x\rightarrow x^{*}$, results:
\begin{equation*}
 |f'(x^{*})|\leq 1.
\end{equation*}

(b) For $\epsilon >0$ exists $\delta$ with the property as $0<\delta<\epsilon$ such that for $|x-x^{*}|$ we have:
\begin{equation*}
 |f(x)-x^{*}|=|f(x)-f(x^{*})|\leq |f'(x^{*})|\cdot |x-x^{*}|,
\end{equation*}
How $|f'(x^{*})|\leq 1$ then $f$ is a cvasicontraction on $(x^{*}-\delta,x^{*}+\delta)$ and applying \ref{2.3.2.2.} we deduce that:
\begin{equation*}
 |x_{n}(x_{0})-\xstar|\leq |f'(\xstar)|^{n}\cdot |x_{0}-\xstar|,\forall x_{0} \in (\xstar-\delta,\xstar+\delta),
\end{equation*}
meaning
\begin{equation*}
 |x_{n}(x_{0})-\xstar|\leq |f'(\xstar)|^{n}\cdot \delta<\epsilon,
\end{equation*}
which proves that $\xstar$ is locally stable. In addition
$$|x_{n}(x_{0})-\xstar|\leq|f'(\xstar)|^{n}\cdot\delta\rightarrow 0, n\rightarrow \infty,$$
so $\xstar$ is locally asimptotic stable.
(c) is an immediat consequence of point (a).


\end{proof}
\begin{theorem}
\label{2.3.2.4.}
 Let $\xstar\in I$ be an equilibrium point for \eqref{2.14},$f:I\rightarrow\R$ such that $f'(\xstar)$ exists and $f'(\xstar)=1$. Then:
 \begin{enumerate}
  \item if $f''(\xstar)$ exists and $f''(\xstar)\neq 0$ then $\xstar$ is unstable;
  \item if $f''(\xstar)$ exists and $f'''(\xstar)$ such that $f''(\xstar)=0$ and $f'''(\xstar)>0$, then $\xstar$ is unstable;
  \item if $f''(\xstar)$ exists and $f'''(\xstar)$ such that $f''(\xstar)=0$ and $f'''(\xstar)<0$, then $\xstar$ is locally asymptotic stable. 
 \end{enumerate}

\end{theorem}
\begin{proof}
 Let us consider the difference equation:
 \begin{equation}\label{2.19}
  y_{n+1}=g(y_{n}),
 \end{equation}
where 
$$g(x)=f^{2}(x)=(f\circ f)(x).$$
Obviously,if $\xstar$ is an equilibrium point for \eqref{2.14}, then $\xstar$ is also an equilibrium point for \eqref{2.19}. We will demonstrate that if $\xstar$ is a locally asimptotic stable point for \eqref{2.19}, then it is also a locally asimptotic stable point for \eqref{2.14}. For a fixed $\epsilon>0$ exists $\delta>0$ such that for all $x$ that satisfy $|x-\xstar|<\delta$ takes place:
\begin{align*}
 |f(x)-\xstar|\leq|f(\xstar)|\cdot |x-\xstar|=|x-\xstar|,\\
 |g^{n}(x)-\xstar|<\epsilon,|g^{n}(x)-\xstar|\rightarrow 0, n\rightarrow \infty.
\end{align*}
So, for a chosen$x_{0}$, such that $|x_{0}-\xstar|<\delta$, we have that also
$$|f(x_{0})-\xstar|\leq|x_{0}-\xstar|<\delta,$$
resulting that 
$$|g^{n}(x_{0})-\xstar|<\epsilon, |g^{n}(f(x_{0}))-\xstar|<\epsilon$$
and
$$|g^{n}(x_{0})-\xstar|\rightarrow 0, |g^{n}(f(x_{0}))-\xstar|\rightarrow 0, n\rightarrow \infty,$$
but
$$y_{n}(x_{0})=g^{n}(x_{0})=x_{2n}(x_{0}), y_{n}(f(x_{0}))=g^{n}(f(x_{0}))=x_{2n+1}(x_{0}),$$
so
$$|x_{n}(x_{0})-\xstar|<\epsilon, |x_{n}(x_{0})-\xstar|\rightarrow 0, n\rightarrow \infty,$$
meaning that $\xstar$ is locally asimptotic stable also for \eqref{2.14}.
\end{proof}

\begin{theorem}
\label{2.3.2.5.}
 Let $\xstar$ be an equilibrium point of \eqref{2.14}. If $f\in C^{3}(\R)$ and $f'(\xstar)=-1$, then:
 \begin{enumerate}
  \item if $-3[f''(\xstar)]^{2}-2f'''(\xstar)<0$, then $\xstar$ is locally asymptotic stable;
  \item if $-3[f''(\xstar)]^{2}-2f'''(\xstar)>0$, then $\xstar$ is unstable;
 \end{enumerate}
\end{theorem}

\begin{theorem}
\label{2.3.2.6.}
 Let $\xstar$ to be an equilibrium point of \eqref{2.14}. If $f\in C^{k}(\R),k\geq 2$ and $f'(\xstar)=1$, $f^{(j)}(\xstar)=0, j=\overline{2,k-1}$, $f^{(k)}(\xstar)\neq 0$, then:
 \begin{enumerate}
  \item if k is even, then $\xstar$ is unstable;
  \item if k is odd and $f^{(k)}(\xstar)>0$, then $\xstar$ is unstable;
  \item if k is odd and $f^{(k)}(\xstar)<0$, then $\xstar$ is asymptotically stable.
 \end{enumerate}

\end{theorem}
\begin{lemma}
 Suppose that $f(x)\in \mathbf{C(\R)}$ and $f'(\xstar)=-1$. 
 \begin{enumerate}
  \item If $\xstar$ is an equilibrium point for \eqref{2.14}, then it is an equilibrium point for \eqref{2.19};
  \item If the equilibrium point $\xstar$ is locally asymptotic stable with respect to \eqref{2.19}, then it is also locally asymptotic stable for \eqref{2.14};
  \item If the equilibrium point $\xstar$ of \eqref{2.14} is unstable with respect to \eqref{2.19}, then it is unstable with respectto \eqref{2.14}.
 \end{enumerate}

\end{lemma}
\begin{theorem}
 Let $\xstar$ to be an equilibrium point of \eqref{2.14}. Suppose that $f\in \mathbf{C}^{2k-1}(\R)$ and $f'(\xstar)=-1, f^{(j)}(\xstar)=0 (j=\overline{2,k-1}), f^{(k)}(\xstar)\neq 0.$
 \begin{enumerate}[i)]
  \item If k is odd and $f^{(k)}(\xstar)>0$, then $\xstar$ is asymptotically stable.
  \item If k is odd and $f^{(k)}(\xstar)<0$, then $\xstar$ is unstable.
  \item Assume that k is even, and there exists an integer $l<k$ such that:
  $$f^{(j)}(\xstar)=0 (j=\overline{(k+1,2l-3)}), f^{(2l-1)}(\xstar)\neq 0$$
  \begin{enumerate}[a)]
   \item If $f^{(2l-1)}(\xstar)>0$, then $\xstar$ is asymptotically stable.
   \item If $f^{(2l-1)}(\xstar)<0$, then $\xstar$ is unstable.
  \end{enumerate}
 \item Assume that k is even, and:
 $$f^{j}(\xstar)=0 (j=\overline{k+1,2k-3}).$$
 \begin{enumerate}[a)]
  \item If $\frac{k}{2}(\frac{f^{(k)}(\xstar)}{k!})^{2} + \frac{f^{(2k-1)}(\xstar)}{(2k-1)!}>0$, then $\xstar$ is asymptotically stable.
  \item If $\frac{k}{2}(\frac{f^{(k)}(\xstar)}{k!})^{2} + \frac{f^{(2k-1)}(\xstar)}{(2k-1)!}<0$, then $\xstar$ is unstable.
 \end{enumerate}

 \end{enumerate}

\end{theorem}
\paragraph{Application}
We consider te stability of the zero solution of
\begin{equation}\label{2.20}
 x_{n+1}=x_{n}e^{-x_{n}^{k}}, n\in\mathbb{N},
\end{equation}
where $x_{n}\in\R$ and $k$ is a positive integer.
\begin{theorem}
 If k is even, then the zero solution of \eqref{2.20} is asymptotically stable. If k is odd, then the zero solution of \eqref{2.20} is unstable.
\end{theorem}
\begin{proof}
 Let $f(x)=xe^{-x^{k}}$. Then we have:
 \begin{align*}
  f(x)&=x\bigg(1+(-x^{k})+\frac{1}{2!}(-x^{k})^{2}+\frac{1}{3!}(-x^{k})^{3}+...\bigg)\\
  &=x=x^{k+1}+\frac{1}{2!}x^{2k+1}-\frac{1}{3!}x^{3k+1}....
 \end{align*}
Thus we have
$$f'(0)=1, f^{(j)}(0)=0, (j=\overline{2,k}), f^{(k+1)}(0)=-(k+1)!<0$$
Using Theorem \ref{2.3.2.6.}, we complete the proof.
\end{proof}

\subsection{Examples}

\subsubsection{Depreciation}

Depreciation refers to the process in which a credit is paid through a series of periodic payments. Each payment covers both the primary credit and the interest rates.\\
Let $p(n)$ be the remaining credit of the $n$ payment and $g(n)$ the percentage of the interest rate equal to $"r"$. \\
The model is based on the idea that the primary credit $p(n+1)$ is equal to the $p(n)$ credit plus the interest rate $rp(n)$ corresponding to the $n$ periods and minus the $n$ payment $g(n)$. So:
\begin{align*}
 p(n+1)=p(n)+rp(n)-g(n)\\
 p(n+1)=(1+r)p(n)-g(n).
\end{align*}
Usually in practice the rate $g(n)=T$, which is constant. Resulting:
\begin{equation}
 p(n)=(1+r)^{n}p(0)-\frac{T}{r}[(1+r)^{n}-1].
\end{equation}
If we wish to pay the credit in exactly "$n$" payments, then $T$ should be (if $p(n)=0$):
$$T=p_{0}\cdot\frac{r}{1-(1+r)^{-n}}$$ 

\subsubsection{Example 2} If exists, find the equilibruim points and specify their type for the following equations:\\ \\
a) $x(n+1)=\frac{1}{3}x^{3}(n)+x(n)$\\ \\
\textbf{Solution:}
In this case, $f(x)=\frac{1}{3}x^{3}+x$. To find the equilibruim point, we must solve $f(x)=x$. Meaning that we have:
$$\frac{1}{3} x^{3}+x=x \Rightarrow x^{3}=0 \Rightarrow x=0.$$
So the only equilibrium point for the given equation is $x=0$. In order to apply Theorem \ref{2.3.2.4.}, we need to find the value of $f'(0), f''(0)$ and $f'''(0).$ 
$$f'(x)=x^{2}+1;$$
$$f''(x)=2x$$ and
$$f'''(x)=2.$$
Resulting that $f'(0)=1$, $f''(0)=0$ and $f'''(0)=2$. Hence, $x=0$ is an unstable equilibrium point.\\

b) $x(n+1)=\tan^{-1}{x(n)}$ \\ \\
\textbf{Solution:}\\

In this case, $f(x)=\tan^{-1}{x}$. If $f(x)=x$, we obtain that $x\tan{x}=1$, resulting that the difference equation does not have equilibrium points. \\ \\
c) $x(n+1)=-x^{3}(n)-x(n)$\\
In this case, $f(x)=-x^{3}-x$. Solving $f(x)=x$, we obtain the equilibrium point $x=0$. $f'(x)=-3x^{2}-1$, meaning that $f'(0)=1$. $f''(x)=-6x$ resulting $f''(0)=0$ and $f'''(x)=-6$ then $f'''(0)=-6$. Hence, by applying Theorem \ref{2.3.2.5.}, we get that $x=0$ is an unstable equilibrium point. 

\subsubsection{Example 3} Let $x(n+1)=x^{2}(n)+3x(n)$. Find the equilibrium point and specify its stability.

\textbf{Solution:}\\
By applying the formula, we denote that $f(x)=x^{2}+3x$. To find the equilibrium point, we need to solve $f(x)=x$. We get $x^{2}+2x=0$, meaning that we have two equilibrium points $x^{o}_{1}=0$ and $x_{2}^{o}=-2$. Knowing that $f'(x)=2x+3$, we get that $f'(0)=3>0$, resulting that $x_{1}^{o}=0$ is unstable according to Theorem \ref{2.3.2.6.}. For $x_{2}^{o}=-2$, we have $f'(-2)=-1<0$, resulting that we can apply Theorem \ref{2.3.2.5.}. Thus we have $f''(x)=2$ and $f'''(x)=0$ resulting that $-3\cdot [f''(-2)]^{2}-2\cdot f'''(-2)=-3\cdot 2^{2}-0=-3\cdot 4=-12<0 \Rightarrow x_{2}^{o}$ is locally asimptotic stable. 

\subsubsection{An application from economics} 

Let $S(n)$ be the number of units from a merchandise supplied on the market in period $"n"$. Let $D(n)$ be the number of units from the same commodity demanded in period $"n"$. Let $p(n)$ be the price/unit in period $"n"$. We presume that:
\begin{equation}
 \begin{cases} \label{2.21}
  D(n)=-m_{d}\cdot p(n)+b_{d} \\
  m_{d},b_{d}>0.
 \end{cases}
\end{equation}
\underline{Assumption:} $D(n)$ depends linearly on $p(n)$. Equation \eqref{2.21} is also called the price-demand curve. $m_{d}$ represents the consumers' sensitivity constant at price. It is certain that $m_{d}$ should be positive as the growth of $p(n)$ implies the declining of the demand. \\
We presume:
\begin{equation}
 \begin{cases} \label{2.22}
  S(n+1)=-m_{s}\cdot p(n)+b_{s} \\
  m_{s},b_{s}>0.
 \end{cases}
\end{equation}
Equation \eqref{2.22} represents the price-offer curve.
\underline{Assumption:} The offer in period $n+1$ depends linearly on the price from the previous period.
\underline{Assumption:} The price from the market is the price to which the supplied quantity equals the demanded quantity, for example: $D(n+1)=S(n+1)\Rightarrow$
\begin{equation}\label{2.23}
 p(n+1)=A\cdot p(n)+B,
\end{equation}
where $A=-\frac{m_{s}}{m_{d}}$ and $B=\frac{b_{d}-b_{s}}{m_{d}}.$
We obtained a first order difference equation. The equilibrium price results from the intersection between the price-offer curve and the price-demand curve. If we note $f(p(n)):=Ap(n)+B$, then $p^{*}$ (equilibrium price) is the only fixed point of $f(p)$. For example:
$$p^{*}=f(p^{*})\Leftrightarrow p^{*}=Ap^{*}+B \Rightarrow p^{*}=\frac{B}{1-A}.$$
We denote three important cases:
\begin{enumerate}[i]
 \item $A\in (-1,0) \Rightarrow p^{*}$ is asymptotically stable;
 \item $A=-1\Rightarrow$ The prices are oscilating between two values. For example, if $p(0)=p_{0}\Rightarrow p(1)=-p_{0}+B. p(2)=p_{0} \Rightarrow$ $p^{*}$ is stable;
 \item $A<-1\Rightarrow$ the prices are oscilating towards infinity $\Rightarrow p^{*}$ is unstable.
\end{enumerate}
The explicit solution of equation \eqref{2.23} is:
$$p(n)=\bigg(p_{0}-\frac{B}{1-A}\bigg)\cdot A^{n}+\frac{B}{1-A}.$$
\underline{Conclusions:}
If the bidders are less sensitive to the prices, than the consumers $(m_{s}<m_{d}\Rightarrow A\in(-1,0))$ then the market is stable. Otherwise, it becomes unstable.
\subsubsection{The linear Cobweb model}
Let us consider the agricultural markets. The idea is that farmers determine how much to supply in period $t$ based on the expectations regardingthe price in period $t$. This helps the farmers estimate how much to seed now considering the future potential profit on the market.
We will assume the expected price to be the same with the price from the previous period. Consider the following simple linear model of demand and supply:
\begin{align}
 qd(t)=a-bp(t) \\
 qs(t)=c+d\cdot pe(t)\\
 pe(t)=p(t-1)\\
 q(t)=qd(t)=qs(t)
\end{align}
where $qd(t)$ represents the quantity demanded, $qs(t)$ represents the quantity supplied, $pe(t)$ the estimated price and $p(t)$ the price. First, we replace the expected price in the second equation by the price in the previous period. Since equilibrium demand is equal to supply, we can equate these two. We obtain:
\begin{align*}
 a-bp(t)=c+dp(t-1)\Rightarrow \\
 p(t)=\frac{a-c}{b}-\frac{d}{b}p(t-1).
\end{align*}
If the system is in equilibrium, results that $p(t-1)=p(t)=p^{*}$. Thus, $p^{*}=\frac{a-c}{b+d}$ and $q^{*}=\frac{ad+bc}{b+d}$, where $a$ represents the speed of adjustment.
On a spreadsheet, where $d=2.5$, the graphic would look like in Figure 2.1.
\begin{figure}[h]\label{cobweb}
\caption{Graphic on a spreadsheet}
\centering
 \includegraphics[width=10cm]{Cobweb.PNG}
\end{figure}
and the Cobweb diagram would look like in Figure 2.2.
\begin{figure}[h]
\caption{Cobweb diagram for initial values from speadsheet.}
\centering
 \includegraphics[width=10cm]{cobwebdiagramfirstexample.png}
\end{figure}
It is interesting to see what happens if we change parameter $d$ from $2.5$ to $5.5$. The system still oscilates, but it is unstable and the price and quantity diverges from the equilibrium. The main observation is that ratio $\frac{d}{b}>1$ compared to the value of d before, when the ratio was $\frac{d}{b}<1$. So the stability of the system depends on the ratio $\frac{d}{b}$. As a conclusion, we can ennounce that if the ratio is less than $1$, the system is oscilatory but convergent. Else if ratio is greater than unit, the system is oscilatory but divergent. The system's stability does not depend on the values of $a$ and $c$. These values only change the equilibrium values.
\begin{figure}[h]
\caption{When ratio is grater than the unit.}
\centering
 \includegraphics[width=10cm]{cobwebratioabove1.PNG}
\end{figure}
When ratio is equal to the unit, both price and quantity oscilate between two values. This repeated oscilation occurs when the slope of the demand curve is equal to the slope of the supply curve. Further, we notice that one of the two prices is the same as the initial value of the price, which always happends when ratio is $1$.
\begin{figure}[h]
\caption{When ratio is equal to the unit.}
\centering
 \includegraphics[width=10cm]{CobwebRatio1.PNG}
\end{figure}

\subsubsection{Keynesian cross diagram}
Let us consider the following economic model:
\begin{align*}
 C=a+bY\\
 E=C+I+G\\
 Y=E
\end{align*}
where $C$ is consumption expenditure, $I$ represents investment expenditures, $G$ government expenditures, $Y$ the national income and $E$ total expenditures. $a$ represents the autonomous consumption and $b$ the marginal propensity to consume.
Investment and government expenditures are treated as exogenous variables. Let us substitute in the second equation the consumption, and we get:
\begin{equation*}
 E=a+bY+I+G
\end{equation*}
and then in the third equation from the model we shall replace total expenditures with the equation above:
\begin{equation*}
 Y=a+bY+G+I
\end{equation*}
meaning that the equilibrium national income would be:
\begin{equation}
 Y^{*}=\frac{a+G+I}{1-b}.
\end{equation}
Let us analyse the behaviour of the model if some changes occur. A rise in investment, from $I_{1}$ to $I_{2}$ would raise the expenditure parallel to itself, which leads to a higher level of equilibrium income $Y_{2}$, as against $Y_{1}$. We get the following equilibrium expressions:
\begin{align*}
 Y_{1}^{*}=\frac{a+I_{1}+G}{1-b}\\
Y_{2}^{*}=\frac{a+I_{2}+G}{1-b}\\
\Delta Y=Y^{*}_{2}-Y^{*}_{1}=\frac{I_{2}-I_{1}}{1-b}=\frac{\Delta I}{1-b}.
 \end{align*}
We will denote $k$ to be the multiplier: $k=\frac{\Delta Y}{\Delta I}=\frac{1}{1-b}$. Further, we will present how the economy reaches $E_{2}$ from equilibrium $E_{2}$. The first rise in investments will rise the expenditures exactly with the same quantity $\Delta I$ which represents the distance between the two lines at the level of income $Y_{2}$. At the current level of income $Y_{1}$ and the level $E_{2}$ of expenditures, there is excess demand in the economy and the stocks begin to colapse. In this model, the price is constant. In order to rebuild the stocks, the supply will suffer a raise in the next period. The production will be grown by the existing labour force or more workers will be hired. The national income rises. In the next step, the expenditures are still above incomes, but less than in the previous period, meaning that stocks are still falling. When stocks will rise, the income will also rise. The described process continues until equilibrium $Y_{2}$ is reached.
If the investment drops, the steps for adjustment are opposites. At the existing level of income, the expenditures drop and stocks will rise. With the increase of stocks in inventories, the comerciants will order less. The production and income drop. The process continues until the new lesser equilibrium income is reached. The model is static due to its immediat adjustment from one equilibrium to another. With these being pointted out, it does not depend on time. Next, let us reconsider the model in a simple dynamic context. We assume that consumption and expenditure in period t is related to income in the same period $Y(t)$ and we assume that investment expenditure and government expenditure are exogenous. $E(t)$ is defined as the sum of all expenditures in time period $t$. We also assume that income adjusts by a ratio $\lambda$ of the excess demand, which is $E(t)-Y(t)$. The model is:
\begin{align*}
 C(t)=a+bY(t)\\
 E(t)=C(t)+I+G\\
 \Delta Y(t+1)=\lambda(E(t)-Y(t)), \lambda>0
\end{align*}
First, in equilibrium we have $\Delta Y(t+1)>0\Rightarrow E(t)=Y(t),\forall t\in\R$. Substituing the first equation into the second and the second into the third leads to the following difference equation:
\begin{equation}\label{keynesiandiffeq}
 \Delta Y(t+1)=\lambda(a+I+G)-\lambda(1-b)Y(t).
\end{equation}
In equilibrium, we get:
$$Y^{*}=\frac{a+I+G}{1-b}.$$
We notice that the equilibrium condition does not depend on $\lambda$. Next, we write the difference equation as a recursive one in order to see the adjustment process in operation. We add $Y(t)$ to both sides of \eqref{keynesiandiffeq}. Hence:
\begin{equation}
 Y(t+1)=\lambda(a+I+G)+[1-\lambda(1-b)]Y(t).
\end{equation}
\begin{figure}[h]
\caption{The diagrams explained above. \cite{shone}}
\centering
 \includegraphics[width=8cm]{keynesian.PNG}
 
\end{figure}
Considering $\lambda$ to be the unit leads to the static model ennounced above. The second diagram represents the difference equation version of the model. The third diagram portraits the phase line of the dynamic model, which is derived from the diagram above it.
Let us consider a random value for income $Y(0)$, which would be measured on the horizontal axis. Let this be below the equilibrium level. Results $E(0)-Y(0)>0$ and so income in period $1$ is a ratio $\lambda$ of this difference. Since $\lambda>0$, this income in period $t$ is higher than it was in period $0$. At income level $Y(0)$, $\Delta Y(t+1)>0$ resulting a rise of the income. This can be noticed on the phase line when arrow points to the right. In all cases, the economy is experiencing a rise in income and is racing towards the equilibrium level of income. If we choose $Y(0)$ above the equilibrium level, results $E(0)-Y(0)<0$ hence income falls, and the arrow from the phase portrait is pointing to the left.



\section{Conclusions}
Dynamic systems generated by difference equations appear in many mathematical models used in fields such as chemistry, biology, physics, economy and so on. They represent a useful tool in describing real behaviors and finding the equilibruim state of the models.  We witnessed how the notions described above helped in solving real economic matters which appeared in specific times with the evolution of the civilization. For example the Keynesian models were used as a strategy to adjust the economy during he Great Depression.



\begin{thebibliography}{9}

 \bibitem{serban2}
  Octavian Agratini, M.A. \c{S}erban, Veronica Ilea. \textit{Matematic\u{a} aplicat\u{a},} Casa C\u{a}r\c{t}ii de \c{S}tiin\c{t}\u{a}, Cluj-Napoca 2017 (Romanian). 

 \bibitem{khankey}
 Sal Khan. \textit{Keynesian Cross}
 \\\texttt{https://www.khanacademy.org/economics-finance-domain/macroeconomics/\\income-and-expenditure-topic/keynesian-cross-tutorial/v/keynesian-cross}
 
  \bibitem{khanislm}
 Sal Khan. \textit{IS-LM model}
 \\\texttt{https://www.khanacademy.org/economics-finance-domain/macroeconomics/\\income-and-expenditure-topic/is-lm-model-tutorial/v/investment-and-real\\-interest-rates}
 
  \bibitem{morosanu}
 G. Moro\c{s}anu. \textit{Ecua\c{t}ii Diferen\c{t}iale. Aplica\c{t}ii}. Editura Academiei Republicii Socialiste Romania, Bucure\c{s}ti 1989 (Romanian).
 
  \bibitem{murakami}
 Kouichi Murakami. \textit{Stability for non-hyperbolic fixed points of scalar difference equations}, 27 September 2004.
 \\\texttt{https://www.sciencedirect.com/science/article/pii/S0022247X0500106X}
 
 \bibitem{perko}
 Lawrence Perko. \textit{Differential Equations and Dynamical Systems. Third Edition}. Springer 2001.
 
 \bibitem{precup}
 Radu Precup. \textit{Ecua\c{t}ii Diferen\c{t}iale}, RISOPRINT, Cluj-Napoca 2011 (Romanian).
 
 \bibitem{rus}
 Ioan A. Rus. \textit{Ecua\c{t}ii Diferen\c{t}iale, ecua\c{t}ii integrale \c{s}i sisteme dinamice.} Transilvania Press, Cluj-Napoca 1996 (Romanian).

 \bibitem{serban1}
  M.A. \c{S}erban. \textit{Ecua\c{t}ii \c{s}i sisteme de ecua\c{t}ii diferen\c{t}iale}, Presa Unviersitar\u{a} Clujean\u{a}, Cluj-Napoca 
  2009 (Romanian).
  
 
 \bibitem{shone}
 Ronald Shone. \textit{An introduction to economic dynamic.} Cambridge University Press, 2003.


\end{thebibliography}


\end{document}
